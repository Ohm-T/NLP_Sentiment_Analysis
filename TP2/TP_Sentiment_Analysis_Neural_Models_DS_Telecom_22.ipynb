{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfkpXKBIthcS"
      },
      "source": [
        "# Text classification with Pytorch\n",
        "\n",
        "The goal of this TP is double: an introduction to using Pytorch for treating textual data, and implementing neural classification models that we can apply to IMDB data - and then compare to models implemented in the previous TPs. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tom Salembien & Lilian Biscarrat"
      ],
      "metadata": {
        "id": "4XzKe-g5Buk6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FH7c_eMyte-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b2bca7-23c7-4ad0-cf6c-18ddd84fc5a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim==4.0.1 in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.0.1) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.0.1) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==4.0.1) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim==4.0.1\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG1Tv5TLtpjP"
      },
      "source": [
        "## 1 - A (very small) introduction to pytorch\n",
        "\n",
        "Pytorch Tensors are very similar to Numpy arrays, with the added benefit of being usable on GPU. For a short tutorial on various methods to create tensors of particular types, see [this link](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py).\n",
        "The important things to note are that Tensors can be created empty, from lists, and it is very easy to convert a numpy array into a pytorch tensor, and inversely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb3h3-OEtuHz",
        "outputId": "55dc87e3-024b-4df6-9dd0-05e340c89e15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([          119230592,                  27,          4294967295,\n",
            "        4908972153413002606, 7214836307739637349])\n",
            "tensor([5])\n"
          ]
        }
      ],
      "source": [
        "a = torch.LongTensor(5)\n",
        "b = torch.LongTensor([5])\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EohavgcYtv6f",
        "outputId": "6b1a3b86-9e01-4178-f14a-bad6a5f03755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.])\n"
          ]
        }
      ],
      "source": [
        "a = torch.FloatTensor([2])\n",
        "b = torch.FloatTensor([3])\n",
        "\n",
        "print(a + b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ7gaHMpt0fV"
      },
      "source": [
        "The main interest in us using Pytorch is the ```autograd``` package. ```torch.Tensor```objects have an attribute ```.requires_grad```; if set as True, it starts to track all operations on it. When you finish your computation, can call ```.backward()``` and all the gradients are computed automatically (and stored in the ```.grad``` attribute).\n",
        "\n",
        "One way to easily cut a tensor from the computational once it is not needed anymore is to use ```.detach()```.\n",
        "More info on automatic differentiation in pytorch on [this link](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGHcybvEty-E",
        "outputId": "58e806bd-5140-4352-9432-6450e55fc5e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor(1., requires_grad=True)\n",
        "w = torch.tensor(2., requires_grad=True)\n",
        "b = torch.tensor(3., requires_grad=True)\n",
        "\n",
        "# Build a computational graph.\n",
        "y = w * x + b    # y = 2 * x + 3\n",
        "\n",
        "# Compute gradients.\n",
        "y.backward()\n",
        "\n",
        "# Print out the gradients.\n",
        "print(x.grad)    # x.grad = 2 \n",
        "print(w.grad)    # w.grad = 1 \n",
        "print(b.grad)    # b.grad = 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b2WNPUetzA-",
        "outputId": "83b7f002-b10c-49c4-d7c2-8ec1ae439b72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight\n",
            "Parameter containing:\n",
            "tensor([[ 0.1557, -0.2846, -0.3763],\n",
            "        [-0.2344,  0.2845,  0.2125]], requires_grad=True)\n",
            "bias\n",
            "Parameter containing:\n",
            "tensor([-0.4511, -0.4692], requires_grad=True)\n",
            "Initial loss:  1.5962646007537842\n",
            "dL/dw:  tensor([[ 0.1828, -0.3578, -0.3495],\n",
            "        [ 0.1518,  0.3217, -0.6744]])\n",
            "dL/db:  tensor([-0.6506, -0.8466])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(10, 3)\n",
        "y = torch.randn(10, 2)\n",
        "\n",
        "# Build a fully connected layer.\n",
        "linear = nn.Linear(3, 2)\n",
        "for name, p in linear.named_parameters():\n",
        "    print(name)\n",
        "    print(p)\n",
        "\n",
        "# Build loss function - Mean Square Error\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Forward pass.\n",
        "pred = linear(x)\n",
        "\n",
        "# Compute loss.\n",
        "loss = criterion(pred, y)\n",
        "print('Initial loss: ', loss.item())\n",
        "\n",
        "# Backward pass.\n",
        "loss.backward()\n",
        "\n",
        "# Print out the gradients.\n",
        "print ('dL/dw: ', linear.weight.grad) \n",
        "print ('dL/db: ', linear.bias.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCZynIQFtzD0",
        "outputId": "a314a869-6795-4cad-baaf-bd0ccba1e80e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after one update:  1.5763980150222778\n"
          ]
        }
      ],
      "source": [
        "# You can perform gradient descent manually, with an in-place update ...\n",
        "linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
        "linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n",
        "\n",
        "# Print out the loss after 1-step gradient descent.\n",
        "pred = linear(x)\n",
        "loss = criterion(pred, y)\n",
        "print('Loss after one update: ', loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXaI-9Z9tzGt",
        "outputId": "852c3772-eae0-40c6-f759-e24f48bd5517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after two updates:  1.557247519493103\n"
          ]
        }
      ],
      "source": [
        "# Use the optim package to define an Optimizer that will update the weights of the model.\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
        "\n",
        "# By default, gradients are accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
        "# is called. Before the backward pass, we need to use the optimizer object to zero all of the\n",
        "# gradients.\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "\n",
        "# Calling the step function on an Optimizer makes an update to its parameters\n",
        "optimizer.step()\n",
        "\n",
        "# Print out the loss after the second step of gradient descent.\n",
        "pred = linear(x)\n",
        "loss = criterion(pred, y)\n",
        "print('Loss after two updates: ', loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjcyC09ct9Nn"
      },
      "source": [
        "## 2 - Tools for data processing \n",
        "\n",
        "```torch.utils.data.Dataset``` is an abstract class representing a dataset. Your custom dataset should inherit ```Dataset``` and override the following methods:\n",
        "- ```__len__``` so that ```len(dataset)``` returns the size of the dataset.\n",
        "- ```__getitem__``` to support the indexing such that ```dataset[i]``` can be used to get the i-th sample\n",
        "\n",
        "Here is a toy example: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OAZi4yvpuAyG"
      },
      "outputs": [],
      "source": [
        "toy_corpus = ['I walked down down the boulevard',\n",
        "              'I walked down the avenue',\n",
        "              'I ran down the boulevard',\n",
        "              'I walk down the city',\n",
        "              'I walk down the the avenue']\n",
        "\n",
        "toy_categories = [0, 0, 1, 0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I0s6D6VOuCNc"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    # A pytorch dataset class for holding data for a text classification task.\n",
        "    def __init__(self, data, categories):\n",
        "        # Upon creating the Dataset object, store the data in an attribute\n",
        "        # Split the text data and labels from each other\n",
        "        self.X, self.Y = [], []\n",
        "        for x, y in zip(data, categories):\n",
        "            # We will propably need to preprocess the data - have it done in a separate method\n",
        "            # We do it here because we might need corpus-wide info to do the preprocessing \n",
        "            # For example, cutting all examples to the same length\n",
        "            self.X.append(self.preprocess(x))\n",
        "            self.Y.append(y)\n",
        "                \n",
        "    # Method allowing you to preprocess data                      \n",
        "    def preprocess(self, text):\n",
        "        text_pp = text.lower().strip()\n",
        "        return text_pp\n",
        "    \n",
        "    # Overriding the method __len__ so that len(CustomDatasetName) returns the number of data samples                     \n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "   \n",
        "    # Overriding the method __getitem__ so that CustomDatasetName[i] returns the i-th sample of the dataset                      \n",
        "    def __getitem__(self, idx):\n",
        "           return self.X[idx], self.Y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cmjsfRZPuCQc"
      },
      "outputs": [],
      "source": [
        "toy_dataset = CustomDataset(toy_corpus, toy_categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxyTBFp6uGaL",
        "outputId": "53a952ff-e1f6-442c-c819-1628505253b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "('i walked down down the boulevard', 0)\n",
            "('i walked down the avenue', 0)\n",
            "('i ran down the boulevard', 1)\n",
            "('i walk down the city', 0)\n",
            "('i walk down the the avenue', 0)\n"
          ]
        }
      ],
      "source": [
        "print(len(toy_dataset))\n",
        "for i in range(len(toy_dataset)):\n",
        "    print(toy_dataset[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdtlHKpJuKwY"
      },
      "source": [
        "```torch.utils.data.DataLoader``` is what we call an iterator, which provides very useful features:\n",
        "- Batching the data\n",
        "- Shuffling the data\n",
        "- Load the data in parallel using multiprocessing workers.\n",
        "and can be created very simply from a ```Dataset```. Continuing on our simple example: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WAk7_20auGdJ"
      },
      "outputs": [],
      "source": [
        "toy_dataloader = DataLoader(toy_dataset, batch_size = 2, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTvn7nmZuGgE",
        "outputId": "d452742d-3a27-4c32-b1c5-46351aa499e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0\n",
            "Batch: ('i ran down the boulevard', 'i walk down the city'); labels: tensor([1, 0])\n",
            "Batch: ('i walk down the the avenue', 'i walked down the avenue'); labels: tensor([0, 0])\n",
            "Batch: ('i walked down down the boulevard',); labels: tensor([0])\n",
            "Epoch:1\n",
            "Batch: ('i walked down the avenue', 'i walked down down the boulevard'); labels: tensor([0, 0])\n",
            "Batch: ('i ran down the boulevard', 'i walk down the the avenue'); labels: tensor([1, 0])\n",
            "Batch: ('i walk down the city',); labels: tensor([0])\n",
            "Epoch:2\n",
            "Batch: ('i walk down the the avenue', 'i walk down the city'); labels: tensor([0, 0])\n",
            "Batch: ('i ran down the boulevard', 'i walked down down the boulevard'); labels: tensor([1, 0])\n",
            "Batch: ('i walked down the avenue',); labels: tensor([0])\n"
          ]
        }
      ],
      "source": [
        "for e in range(3):\n",
        "    print(\"Epoch:\" + str(e))\n",
        "    for x, y in toy_dataloader:\n",
        "        print(\"Batch: \" + str(x) + \"; labels: \" + str(y))  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lgbEZpbuQLN"
      },
      "source": [
        "## 3 - Data processing of a text dataset\n",
        "\n",
        "Now, we would like to apply what we saw to our case, and **create a specific class** ```TextClassificationDataset``` **inheriting** ```Dataset``` that will:\n",
        "- Create a vocabulary from the data (use what we saw in the previous TP)\n",
        "- Preprocess the data using this vocabulary, adding whatever we need for our pytorch model\n",
        "- Have a ```__getitem__``` method that allows us to use the class with a ```Dataloader``` to easily build batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LXMyhHSfuGl4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "import os.path as op\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brvWrFAHvfzX"
      },
      "source": [
        "First, we get the filenames and the corresponding categories: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWrPRszpuGoY",
        "outputId": "b720c00a-7a61-43c9-883a-c36007b02e46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "To: /content/aclImdb_v1.tar.gz\n",
            "100%|██████████| 84.1M/84.1M [00:05<00:00, 15.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "# For those on google colab: you can download the files directly with this:\n",
        "import gdown\n",
        "gdown.download(\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", output=\"aclImdb_v1.tar.gz\", quiet=False)\n",
        "!tar xzf /content/aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zWxaPdQjuGrm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5301a2f1-2df7-4632-bd72-f95b3386ad57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "# We get the files from the path: ./aclImdb/train/neg for negative reviews, and ./aclImdb/train/pos for positive reviews\n",
        "train_filenames_neg = sorted(glob(op.join('.', 'aclImdb', 'train', 'neg', '*.txt')))\n",
        "train_filenames_pos = sorted(glob(op.join('.', 'aclImdb', 'train', 'pos', '*.txt')))\n",
        "\n",
        "test_filenames_neg = sorted(glob(op.join('.', 'aclImdb', 'test', 'neg', '*.txt')))\n",
        "test_filenames_pos = sorted(glob(op.join('.', 'aclImdb', 'test', 'pos', '*.txt')))\n",
        "\n",
        "# Each files contains a review that consists in one line of text: we put this string in two lists, that we concatenate\n",
        "train_texts_neg = [open(f, encoding=\"utf8\").read() for f in train_filenames_neg]\n",
        "train_texts_pos = [open(f, encoding=\"utf8\").read() for f in train_filenames_pos]\n",
        "train_texts = train_texts_neg + train_texts_pos\n",
        "\n",
        "test_texts_neg = [open(f, encoding=\"utf8\").read() for f in test_filenames_neg]\n",
        "test_texts_pos = [open(f, encoding=\"utf8\").read() for f in test_filenames_pos]\n",
        "test_texts = test_texts_neg + test_texts_pos\n",
        "\n",
        "\n",
        "# The first half of the elements of the list are string of negative reviews, and the second half positive ones\n",
        "# We create the labels, as an array of [1,len(texts)], filled with 1, and change the first half to 0\n",
        "train_labels = np.ones(len(train_texts), dtype=int)\n",
        "train_labels[:len(train_texts_neg)] = 0.\n",
        "\n",
        "\n",
        "test_labels = np.ones(len(test_texts), dtype=np.int)\n",
        "test_labels[:len(test_texts_neg)] = 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2F1biXNv62G"
      },
      "source": [
        "Example of one document:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "2XL0ZBz_uCTX",
        "outputId": "d2841338-2915-4350-ccbc-67f8da8f7214"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "open(\"./aclImdb/train/neg/0_3.txt\", encoding=\"utf8\").read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mad2WjyxwIp_"
      },
      "source": [
        "We can use a function from sklearn, ```train_test_split```, to separate data into training and validation sets:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5VXYzolvv79h"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lOZxlsdHwW8s"
      },
      "outputs": [],
      "source": [
        "train_texts_splt, val_texts, train_labels_splt, val_labels = train_test_split(train_texts, train_labels, test_size=.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTuq86F_w38k"
      },
      "source": [
        "We can now implement our ```TextClassificationDataset``` class, that we will build from:\n",
        "- A list of path to the IMDB files in the training set: ```path_to_file```\n",
        "- A list of the corresponding categories: ```categories```\n",
        "We will add three optional arguments:\n",
        "- First, a way to input a vocabulary (so that we can re-use the training vocabulary on the validation and training ```TextClassificationDataset```). By default, the value of the argument is ```None```.\n",
        "- In order to work with batches, we will need to have sequences of the same size. That can be done via **padding** but we will still need to limit the size of documents (to avoid having batches of huge sequences that are mostly empty because of one very long documents) to a ```max_length```. Let's put it to 100 by default.\n",
        "- Lastly, a ```min_freq``` that indicates how many times a word must appear to be taken in the vocabulary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEv4BW4ow6Qe"
      },
      "source": [
        "The idea behind **padding** is to transform a list of pytorch tensors (of maybe different length) into a two dimensional tensor - which we can see as a batch. The size of the first dimension is the one of the longest tensor - and other are **padded** with a chosen symbol: here, we choose 0. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5HvjckX8wW_Y"
      },
      "outputs": [],
      "source": [
        "tensor_1 = torch.LongTensor([1, 4, 5])\n",
        "tensor_2 = torch.LongTensor([2])\n",
        "tensor_3 = torch.LongTensor([6, 7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TkfZxx6w9E-",
        "outputId": "815f9dbf-f7cb-45ce-8f5c-a0bcec8bf4a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 4, 5],\n",
            "        [2, 0, 0],\n",
            "        [6, 7, 0]])\n"
          ]
        }
      ],
      "source": [
        "tensor_padded = pad_sequence([tensor_1, tensor_2, tensor_3], batch_first=True, padding_value = 0)\n",
        "print(tensor_padded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwuFswSJbzPZ"
      },
      "source": [
        "<div class='alert alert-block alert-info'>\n",
        "            Code:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "o1n5H6RUw9H2"
      },
      "outputs": [],
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, data, categories, vocab = None, max_length = 100, min_freq = 5):\n",
        "        self.data = data      \n",
        "        # Set the maximum length we will keep for the sequences\n",
        "        self.max_length = max_length\n",
        "        \n",
        "        # Allow to import a vocabulary (for valid/test datasets, that will use the training vocabulary)\n",
        "        if vocab is not None:\n",
        "            self.word2idx, self.idx2word = vocab\n",
        "        else:\n",
        "            # If no vocabulary imported, build it (and reverse)\n",
        "            self.word2idx, self.idx2word = self.build_vocab(self.data, min_freq)\n",
        "        \n",
        "        # We then need to tokenize the data .. \n",
        "        tokenized_data = [word_tokenize(self.clean(d)) for d in self.data]\n",
        "        # Transform words into lists of indexes ... (use the .get() method to redirect unknown words to the UNK token)\n",
        "        indexed_data =  [[self.word2idx.get(x, self.word2idx['UNK']) for x in sent] for sent in tokenized_data]\n",
        "        # And transform this list of lists into a list of Pytorch LongTensors\n",
        "        tensor_data = [torch.LongTensor(x) for x in indexed_data]\n",
        "        # And the categories into a FloatTensor\n",
        "        tensor_y = torch.FloatTensor(categories)\n",
        "        # To finally cut it when it's above the maximum length\n",
        "        cut_tensor_data = [x[:self.max_length] for x in tensor_data]\n",
        "        \n",
        "        # Now, we need to use the pad_sequence function to have the whole dataset represented as one tensor,\n",
        "        # containing sequences of the same length. We choose the padding_value to be 0, the we want the\n",
        "        # batch dimension to be the first dimension \n",
        "        self.tensor_data = pad_sequence(cut_tensor_data, True)\n",
        "        self.tensor_y = tensor_y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # The iterator just gets one particular example with its category\n",
        "        # The dataloader will take care of the shuffling and batching\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        return self.tensor_data[idx], self.tensor_y[idx] \n",
        "    \n",
        "    def clean(self, corpus):\n",
        "        # Lower text\n",
        "        corpus = corpus.lower()\n",
        "        # Remove numbers\n",
        "        corpus = re.sub(r\"[0-9]\", \"\", corpus)\n",
        "        # Remove punctuation\n",
        "        REMOVE_PUNCT = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
        "        corpus = REMOVE_PUNCT.sub(\"\", corpus)\n",
        "        # Remove html\n",
        "        REPLACE_HTML = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
        "        corpus = REPLACE_HTML.sub(\" \", corpus)\n",
        "        return corpus\n",
        "\n",
        "    def build_vocab(self, corpus, count_threshold):\n",
        "        \"\"\"\n",
        "        Same as in the previous TP: we want to output word_index, a dictionary containing words \n",
        "        and their corresponding indexes as {word : indexes} \n",
        "        But we also want the reverse, which is a dictionary {indexes: word}\n",
        "        Don't forget to add a UNK token that we need when encountering unknown words\n",
        "        We also choose '0' to represent the padding index, so begin the vocabulary index at 1 ! \n",
        "        \"\"\"\n",
        "        # To complete\n",
        "        voc = dict()\n",
        "        corpus = self.clean(' '.join(corpus)).split()\n",
        "        for word in corpus:\n",
        "                if word not in voc:\n",
        "                    voc[word] = 0\n",
        "                voc[word]+=1\n",
        "        word_counter = dict(sorted(voc.items(), key=lambda t: t[1], reverse=True))\n",
        "        \n",
        "        if count_threshold==0:\n",
        "            count_threshold = len(word_counter)\n",
        "        word_counter = {key : val for key, val in word_counter.items() if val > count_threshold}\n",
        "        word_counter['UNK'] = 0\n",
        "        word_index = dict(zip(word_counter.keys(), range(len(word_counter))))\n",
        "        idx_word = dict(zip(range(len(word_counter)), word_counter.keys()))\n",
        "\n",
        "        return word_index, idx_word\n",
        "    \n",
        "    def get_vocab(self):\n",
        "        # A simple way to get the training vocab when building the valid/test \n",
        "        return self.word2idx, self.idx2word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "CM0NsS3DzYmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f3a672-5887-4238-9463-ef20d3a06f83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "QwA5Jxm3w9Kw"
      },
      "outputs": [],
      "source": [
        "training_dataset = TextClassificationDataset(train_texts_splt, train_labels_splt, min_freq = 5)\n",
        "training_word2idx, training_idx2word = training_dataset.get_vocab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "HBD-W4fzw9NR"
      },
      "outputs": [],
      "source": [
        "valid_dataset = TextClassificationDataset(val_texts, val_labels, (training_word2idx, training_idx2word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "n3ei2xd6JnvS"
      },
      "outputs": [],
      "source": [
        "test_dataset = TextClassificationDataset(test_texts, test_labels, (training_word2idx, training_idx2word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "FvWlJpbRw9Pt"
      },
      "outputs": [],
      "source": [
        "training_dataloader = DataLoader(training_dataset, batch_size = 200, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size = 25)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "LidGZUp-w9SN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5534305-5732-4071-b550-8c10b20d3ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([   13,     0,   107,     3,    67,     8,   173,   817,    41,   133,\n",
            "          253,    57,    89,     2,    15,    36,     9,     0,   108,     5,\n",
            "         1474,     0,   111,     5,  8139,     0,  1092,     5,  4065,  4108,\n",
            "            1,    29,   206,     0,   114,   346,     3,     0,  1760,   674,\n",
            "          464,    36,     2,   568,     3,   790,    11,  9606,    35,   605,\n",
            "         1315,     6,   154,   372,     3, 17884,    13,    47,  4187,   178,\n",
            "           46,     0,   294,  1066,   480,     4,   837, 21936,    11,   546,\n",
            "         4108,     1,   464,     4,   360,    22,   169,   855,     9, 24005,\n",
            "          843,  7556,     1,    23,     2,    47,   454,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), tensor(0.))\n"
          ]
        }
      ],
      "source": [
        "print(training_dataset.__getitem__(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "891JXUwPw9Ux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b877f9e3-c517-43eb-e0f4-6adced795049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([200, 100])\n",
            "torch.Size([200])\n"
          ]
        }
      ],
      "source": [
        "example_batch = next(iter(training_dataloader))\n",
        "print(example_batch[0].size())\n",
        "print(example_batch[1].size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n9XkuTs0GKT"
      },
      "source": [
        "### 4 - A simple averaging model\n",
        "\n",
        "Now, we will implement in Pytorch what we did in the previous TP: a simple averaging model. For each model we will implement, we need to create a class which inherits from ```nn.Module``` and redifine the ```__init__``` method as well as the ```forward``` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBgk2yGwbzPg"
      },
      "source": [
        "<div class='alert alert-block alert-info'>\n",
        "            Code:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "wCmyWWQq0LDS"
      },
      "outputs": [],
      "source": [
        "# Models are usually implemented as custom nn.Module subclass\n",
        "# We need to redefine the __init__ method, which creates the object\n",
        "# We also need to redefine the forward method, which transform the input into outputs\n",
        "\n",
        "class AveragingModel(nn.Module):    \n",
        "    def __init__(self, embedding_dim, vocabulary_size):\n",
        "        super().__init__()\n",
        "        # Create an embedding object. Be careful to padding - you need to increase the vocabulary size by one !\n",
        "        # Look into the arguments of the nn.Embedding class\n",
        "        self.embeddings = nn.Embedding(vocabulary_size+1,embedding_dim, padding_idx=0)\n",
        "        # Create a linear layer that will transform the mean of the embeddings into a classification score\n",
        "        self.linear = nn.Linear(embedding_dim,1)\n",
        "        # No need for sigmoid, it will be into the criterion ! \n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        # Remember: the inpts are written as Batch_size * seq_length * embedding_dim\n",
        "        # First, take the mean of the embeddings of the document\n",
        "        emb = self.embeddings(inputs)\n",
        "        x = torch.mean(emb, dim=1)\n",
        "        # Then make it go through the linear layer and remove the extra dimension with the method .squeeze()\n",
        "        o = torch.squeeze(self.linear(x))\n",
        "        return o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "5VH2C2rE0FR_"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "wZp4RDMW0LGX"
      },
      "outputs": [],
      "source": [
        "model = AveragingModel(300, len(training_word2idx))\n",
        "# Create an optimizer\n",
        "opt = optim.Adam(model.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
        "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucQQX08AbzPj"
      },
      "source": [
        "<div class='alert alert-block alert-info'>\n",
        "            Code:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "JM9MFRVQ0LJh"
      },
      "outputs": [],
      "source": [
        "# Implement a training function, which will train the model with the corresponding optimizer and criterion,\n",
        "# with the appropriate dataloader, for one epoch.\n",
        "\n",
        "def train_epoch(model, opt, criterion, dataloader):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for i, (x, y) in enumerate(dataloader):\n",
        "        opt.zero_grad()\n",
        "        # (1) Forward\n",
        "        pred = model(x)\n",
        "        # (2) Compute the loss \n",
        "        loss = criterion(pred, y)\n",
        "        # (3) Compute gradients with the criterion\n",
        "        loss.backward()\n",
        "        # (4) Update weights with the optimizer\n",
        "        opt.step()       \n",
        "        losses.append(loss.item())\n",
        "        # Count the number of correct predictions in the batch - here, you'll need to use the sigmoid\n",
        "        pred = (torch.sigmoid(pred)>=0.5).float()\n",
        "        num_corrects = (pred==y).sum()\n",
        "        acc = 100.0 * num_corrects/len(y)\n",
        "        \n",
        "        if (i%20 == 0):\n",
        "            print(\"Batch \" + str(i) + \" : training loss = \" + str(loss.item()) + \"; training acc = \" + str(acc.item()))\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-zILiZnbzPk"
      },
      "source": [
        "<div class='alert alert-block alert-info'>\n",
        "            Code:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "vz82AFmL0LMx"
      },
      "outputs": [],
      "source": [
        "# Same for the evaluation ! We don't need the optimizer here. \n",
        "def eval_model(model, criterion, evalloader):\n",
        "    model.eval()\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(evalloader):\n",
        "            pred = model(x)\n",
        "            loss = criterion(pred,y)\n",
        "            pred = (nn.Sigmoid()(pred)>=0.5).float()*1\n",
        "            num_corrects = (pred==y).sum()\n",
        "            acc = 100.0 * num_corrects/len(y)\n",
        "            total_epoch_loss += loss.item()\n",
        "            total_epoch_acc += acc.item()\n",
        "\n",
        "    return total_epoch_loss/(i+1), total_epoch_acc/(i+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "J8grPth70ZyO"
      },
      "outputs": [],
      "source": [
        "# A function which will help you execute experiments rapidly - with a early_stopping option when necessary. \n",
        "def experiment(model, opt, criterion, num_epochs = 5, early_stopping = True):\n",
        "    train_losses = []\n",
        "    if early_stopping: \n",
        "        best_valid_loss = 10. \n",
        "    print(\"Beginning training...\")\n",
        "    for e in range(num_epochs):\n",
        "        print(\"Epoch \" + str(e+1) + \":\")\n",
        "        train_losses += train_epoch(model, opt, criterion, training_dataloader)\n",
        "        valid_loss, valid_acc = eval_model(model, criterion, valid_dataloader)\n",
        "        print(\"Epoch \" + str(e+1) + \" : Validation loss = \" + str(valid_loss) + \"; Validation acc = \" + str(valid_acc))\n",
        "        if early_stopping:\n",
        "            if valid_loss < best_valid_loss:\n",
        "                best_valid_loss = valid_loss\n",
        "            else:\n",
        "                print(\"Early stopping.\")\n",
        "                break  \n",
        "    test_loss, test_acc = eval_model(model, criterion, test_dataloader)\n",
        "    print(\"Epoch \" + str(e+1) + \" : Test loss = \" + str(test_loss) + \"; Test acc = \" + str(test_acc))\n",
        "    return train_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "UZvgnfo10Z1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d54c68-fb7f-4a45-b32e-a4a511dccf28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning training...\n",
            "Epoch 1:\n",
            "Batch 0 : training loss = 0.6979813575744629; training acc = 47.5\n",
            "Batch 20 : training loss = 0.6676254272460938; training acc = 64.5\n",
            "Batch 40 : training loss = 0.6389480829238892; training acc = 68.0\n",
            "Batch 60 : training loss = 0.6129500865936279; training acc = 70.5\n",
            "Batch 80 : training loss = 0.5569121241569519; training acc = 77.5\n",
            "Epoch 1 : Validation loss = 0.5456750822067261; Validation acc = 74.48\n",
            "Epoch 2:\n",
            "Batch 0 : training loss = 0.5288518667221069; training acc = 77.5\n",
            "Batch 20 : training loss = 0.4543701410293579; training acc = 82.5\n",
            "Batch 40 : training loss = 0.4319796860218048; training acc = 84.5\n",
            "Batch 60 : training loss = 0.4197255074977875; training acc = 84.0\n",
            "Batch 80 : training loss = 0.33831149339675903; training acc = 89.5\n",
            "Epoch 2 : Validation loss = 0.4218478917330504; Validation acc = 81.16\n",
            "Epoch 3:\n",
            "Batch 0 : training loss = 0.29656532406806946; training acc = 87.5\n",
            "Batch 20 : training loss = 0.3142245411872864; training acc = 88.5\n",
            "Batch 40 : training loss = 0.3209008276462555; training acc = 87.5\n",
            "Batch 60 : training loss = 0.31437960267066956; training acc = 89.0\n",
            "Batch 80 : training loss = 0.36592042446136475; training acc = 84.5\n",
            "Epoch 3 : Validation loss = 0.37852692380547526; Validation acc = 83.36\n",
            "Epoch 4:\n",
            "Batch 0 : training loss = 0.29553744196891785; training acc = 88.5\n",
            "Batch 20 : training loss = 0.25777196884155273; training acc = 91.5\n",
            "Batch 40 : training loss = 0.2345161885023117; training acc = 90.5\n",
            "Batch 60 : training loss = 0.2519955337047577; training acc = 89.5\n",
            "Batch 80 : training loss = 0.24930433928966522; training acc = 90.0\n",
            "Epoch 4 : Validation loss = 0.36599292457103727; Validation acc = 83.88\n",
            "Epoch 5:\n",
            "Batch 0 : training loss = 0.20127904415130615; training acc = 95.0\n",
            "Batch 20 : training loss = 0.23161791265010834; training acc = 93.5\n",
            "Batch 40 : training loss = 0.26858988404273987; training acc = 91.5\n",
            "Batch 60 : training loss = 0.1941917985677719; training acc = 93.5\n",
            "Batch 80 : training loss = 0.20720112323760986; training acc = 92.0\n",
            "Epoch 5 : Validation loss = 0.36562899842858315; Validation acc = 84.1\n",
            "Epoch 5 : Test loss = 0.4109430378340185; Test acc = 81.372\n"
          ]
        }
      ],
      "source": [
        "train_losses = experiment(model, opt, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "m-CIwDga0Z7q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "b0958a7e-1bee-48ff-d6b9-c4fe56370bad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f20aca917d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deZwcVbXHf6fX2WcyW/ZkshKyB0JIyCIgaBAIPgQE3lNQBERRxOcCKqiICrijuKACCkpAeEIkQNgS1kAWEhKy78lkm33vve/7o+pW36quXmYyk+7pOd/PJ590V1VX3ZpMfnX6d889h4QQYBiGYfo/jkwPgGEYhukdWNAZhmFyBBZ0hmGYHIEFnWEYJkdgQWcYhskRXJm6cGVlpaipqcnU5RmGYfol69evbxBCVNnty5ig19TUYN26dZm6PMMwTL+EiA4k2seWC8MwTI7Ags4wDJMjsKAzDMPkCGkJOhEtJqIdRLSbiG6z2f8rItqo/9lJRC29P1SGYRgmGSknRYnICeABAOcDqAWwloiWCSG2ymOEELcqx38FwKw+GCvDMAyThHQi9DkAdgsh9gohggCWArgkyfFXAXi8NwbHMAzDpE86gj4cwCHlfa2+LQ4iGg1gDIDXEuy/gYjWEdG6+vr67o6VYRiGSUJvT4peCeApIUTEbqcQ4kEhxGwhxOyqKtu8+LR4ddtxrNpR1+PPMwzD5CLpLCw6DGCk8n6Evs2OKwF8+UQHlYwVW47hxkfXAwAunD4UxV4X7rx4Mgo8GVsjxTAMkxWko4JrAUwgojHQhPxKAFdbDyKiSQAGAVjdqyO04HE5cOaYcvjDUSzfdBQA0NQZxK+vnMmizjDMgCalAgohwkR0M4AVAJwAHhJCbCGiuwCsE0Is0w+9EsBS0cctkM45pRpnT6yCLxTBe/uasGZfE/6wag/+64F3MKjQjXljK3HzuePx7t5GzB9f2ZdDYRiGySrSCmmFEM8DeN6y7U7L+x/03rCSQ0Qo8LhwzinVOOeUaoTCUfzlrX0AgHf3NiEYieCBlXvw98/PwaKJPffqGYZh+hM5sVL0exdNxsY7z8eXzh4HAHhg5R4AwL6GzkwOi2EY5qSSE4IOAGUFHnzz46dgTGWhsW13XUcGR8QwDHNyyRlBBzQr5roFY4z3j757AP/1+7fhC2pZlKv3NGLVjjpsOdIKIQT62O5nGIY5qeRcWsj/zB2Nj00ejL0NnfjOvzdjw8EWfPOpDzBzZBnuXr7NOG7i4CLku5149uYFGRwtwzBM75Fzgg4A1SV5qC7Jw2v/ezYu/f3beG7TUTynpzhKdh5nO4ZhmNwipywXOxakSF1s7gyepJEwDMP0LTkv6J9fMAafnTcaBR6n7f57Xth+kkfEMAzTN+S8oJcVeHDXJVPx5I3zMGdMedz+f60/hFU76rBiy7EMjI5hGKb3yHlBl0wdXoonb5yHXT++AAAwsjwfP710GqICuPbhtbjx0fVo84cyPEqGYZieM2AEXeJ2OvDi1xZixdcWYXhZvmnffz44YvuZps4gWrtY7BmGyW4GnKADwKQhJSjwuDB8kFnQV+9ptD3+tB+9jPn32pZ4ZxiGyRoGpKBL1Ai9NN+N9/Y1QQiBcCSKo60+bDjYbCw+6giEMzVMhmGYtMjJPPR0yXM7ceaYcuxv7MSVZ4zCb17dhaOtfvx+1W489u5BAMD46qIMj5JhGCY9BrSgA8ATN84DAKw/0ITfvLoL9724Hc9sjHnpXA+GYZj+woC2XFQmDSkBAJOYMwzD9CdY0HUKvS5cNH1o0mOiUS7mxTBM9sKCrvC7q0/Dy7cuwvcuPNW0/bYLJgEAukK2va8ZhmGyAhZ0CxMGF+MLC8ca73/0yakoyXMDAG56bD2++Oh6+EMRHG/z48v/eB/tvBiJYZgsYcBPiibi5VsXoSjPhaGl+VimLzh6c1cDAGDz4Va8tOUYlm8+ipkjy3D9orHJTsUwDHNSYEFPwITBxcbr4jzzj2lvfQeK9ai9oTNwUsfFMAyTCLZc0sDlIADAlGEl8Lgc2FvfCdnsqLGDy+8yDJMdsKCnwbgqbXHR18+fiDEVhXj4nf3YerQVAHCwscs4LhSJYsuR1oyMkWEYhi2XNBhWlo/991wIAKht9uH7y7ZgxZbjAIDj7X7juP998gMs++AIvr14ErYfa8NvrpyVkfEyDDMw4Qi9m1xzVg0mDo6VAzjQ2IVrHlqDSFQYk6f3vrgdz248gv0NnZkaJsMwAxAW9B4wu8bcKOP1nfW2JQJe2153sobEMAzDgt4TLpoWv6J08+F47/xwiw++IC9GYhjm5MCC3gPmjavAGTWDsHBCrAH1h4qguxyE6mIvNte24tQ7X8S/N9RmYpgMwwwwWNB7ABHhX188C186e7yxTQr60zedhfXfOx9FeS6s2d8EAPjZizsyMk6GYQYWaQk6ES0moh1EtJuIbktwzBVEtJWIthDRP3t3mNnJoEK38XqTLuhThpWgtMCNIm8sgehIq5+tF4Zh+pyUaYtE5ATwAIDzAdQCWEtEy4QQW5VjJgC4HcB8IUQzEVX31YCziUEFHuN1MBxFWYEbeW4nABiCTgQIARxo6jRK9DIMw/QF6UTocwDsFkLsFUIEASwFcInlmOsBPCCEaAYAIcSASO8YXJKH/9y8AJOGaGUCRpUXGPsKdUGfNbIMALC/oSv+BAzDML1IOoI+HMAh5X2tvk1lIoCJRPQ2Eb1LRIvtTkRENxDROiJaV19f37MRZxnTRpTiDD2NcaYu3gCQr0fqM0cOAgDsb+ScdIZh+pbemhR1AZgA4GwAVwH4MxGVWQ8SQjwohJgthJhdVVXVS5fOPNNHlAIApg0vNbZF9GIvI8vzMaw0D+sPNGdkbAzDDBzSWfp/GMBI5f0IfZtKLYD3hBAhAPuIaCc0gV/bK6PMci47fQQGl+SZ0hhD4SgAoLzQgwumDcWjqw+g1RdCab470WkYhmFOiHQi9LUAJhDRGCLyALgSwDLLMc9Ai85BRJXQLJi9vTjOrIaIsGhiFYjI2BaKaIJe4HFhwfhKBCNR7K5rz9QQGYYZAKQUdCFEGMDNAFYA2AbgSSHEFiK6i4iW6IetANBIRFsBrATwTSFEY18Nuj8Q1vuPup2E6hIvAKC+nWunMwzTd6TloQshnhdCTBRCjBNC/FjfdqcQYpn+Wgghvi6EmCyEmCaEWNqXg+4PnDtJy9wcW1mE6uI8AECdLuhHWnzYebwdbf4Qbv7n+yz0DMP0Clw+t4+49qwaXDJzOMoLPYhEBRwUi9DPuuc1AMC9n5qG5zYdRaHHhXsvm57J4TIMkwOwoPcRRITyQm3hkdNBqCjy4h/vHcTpowcZxxR5tQlStaY6wzBMT2FBP0nI6Pzah2OJP1/+5/umfQzDMCcCF+c6ScwbW5FwHws6wzC9AQv6SeLhz52RcJ8/FF+4a+OhFvzyJa7SyDBM+rCgnyRk0S47gpEo/KEIgvpiJAD45ANv4/7Xdhv57AzDMKlgQc8C/KEopv/wJXz812/E7Wv3hzMwIoZh+iMs6CeR3141K+G+YDiKfXpTadVTb/OF+nxcDMPkBizoJ5GLZwzDtWfVpDxOrczIETrDMOnCgn6SWTC+Mun+SFSgtjlWO73dzxE6wzDpwYJ+kjlv8mC8f8f5WPWNs233N3cFcajJZ7xvY0FnGCZNWNAzQHmhBzWVhfjPzQtwz6XTTPvq2wOmCL2NLReGYdKEV4pmkGkjSiEgTNvq2gM42urH2MpC7G3o5ElRhmHShiP0DCN7j0q2HGlFRyCMIaVahUY5KfqXN/fipS3HTvr4GIbpP3CEnmEKPbF/ginDSvDqtjr4ghFUFXlR5HUZHvrdy7cZx93y0Qm49fyJJ32sDMNkNxyhZ5gCb2wF6cUzhmH9gWZsP9aOAo8TRV4XOvxhCGG2Zf7w+p6TPUyGYfoBLOgZRkboZ42rwHULxqBYt2DyPS4UeJ3oCkXQ5jNPjEaiIu48DMMwbLlkGKeD8NKtizBiUD7cTgdKC9xoD4RR4HGi0OPCGzvqsXTtQdNnWNAZhrGDBT0LmDi42HhdpEfoBR4n8j1OtAfC+OkL2zM1NIZh+hFsuWQZHpf2T5LvcaLQk7hCo0pLVxAfHm7ty2ExDNMPYEHPMpwOAgAUuJ0o8KT3Beovb+7D5X9czVYMwwxwWNCzDJcu6PkeJwrSjNAbOgLwhSKo496kDDOgYUHPMhwkBd0Vt+hIJapE43Lx0eFmX6LDGYYZALCgZxkuZ8xy8boT//OoZXXl4qPDLSzoDDOQYUHPMmSE7nQSkMQSb1VqvMgCXrUcoTPMgIYFPcuQHno0KkyTnMUW+0UV9HaO0BmGAQt61lFR5AUAuJ0ORJQl/15Lk2m1TrpcSWr10DfVtqArmLj87tFWn8mLZximf8OCnmXcefFkfOcTk7BgfKUpQve6HHj8+rn4woIxAFJH6G3+EJb87m3csnQjPjzciv98cATBcBTBcBQAUNvchXk/fQ33v7brZNwWwzAngbQEnYgWE9EOItpNRLfZ7L+WiOqJaKP+5wu9P9SBQUmeGzcsGgeHgzB1eKmx/bxTqzFvXAWuW2gW9EA4gkA4CiItQpeFvLoCEQDAB4dacNFv38JXHt+AqT9Ygfn3vgYAON6mNaJeuaP+pN0bwzB9S8qVK0TkBPAAgPMB1AJYS0TLhBBbLYc+IYS4uQ/GOGC5/PQROG3UIHhdDgzV66OX5rsBxARdZruMLi/A/sYuNHeFUF7oQVQXdjnJCgDBcBT17ZqQq169uv+Pr+/BDYvGIs+dXg48wzDZQzoR+hwAu4UQe4UQQQBLAVzSt8NiAICIML66CCPLC+By6iUB3E64nWQI+oHGTgDAFD2aP6LbLtKukStPrUihDyuC/ti7B/DLl3fiz2/s7YO7YRimr0lH0IcDOKS8r9W3WfkUEW0ioqeIaGSvjI6Jg4hQmu82BP1v7xxASZ4LV8zWfuT1HVoEHtC9crLXc4Sj2n41QveFNJumMxjpk7EzDNO39Nak6H8A1AghpgN4GcDf7A4iohuIaB0RrauvZ++2p5Qogr7taBvmjq1ATUUBAKCxIwgAxuRnogg9FNGEPCI4y4VhcoV0BP0wADXiHqFvMxBCNAohAvrbvwA43e5EQogHhRCzhRCzq6qqejJeBlpO+tp9TXhmw2Eca/NjaGkeKvV0x2/86wO8sbMeoYgm6I4EIboUfE5bZJjcIR1BXwtgAhGNISIPgCsBLFMPIKKhytslALaB6TPyPU7UtQfwtSc2ot0fxuDSPFPdlwdW7kbQEHTA44z/Z5aCr0boUvtFsiWqDMNkLSmzXIQQYSK6GcAKAE4ADwkhthDRXQDWCSGWAfgqES0BEAbQBODaPhzzgMdaVndISZ75fWleSstFCj6X3GWY3CGtgttCiOcBPG/Zdqfy+nYAt/fu0JhEWMvqWgW90OsyFhlFosIQb5UQCzrD5By8UrQfYhX0al3QF06oBAA8vb4W33pqEwDAH4oX80hUGBG8KugEw3NhGKYfwoLeD7FaLlXF2oToo9ediZkjy4yURSCWiqgSCEeMCD3KWS4MkzOwoPdD8i0RekleTODLCtymfX47QQ9FEdTTFtWFRVLcQxFhlBBgGKb/wILeDymwLMsnJTVRlgaQdNksEgooRbpUy0VG7Q+9vQ/3vLAdgNbe7r4XtyNs48MzDJNdsKD3Q6wRukqZRdDtMFkuNoIOAH9ffQAA8MP/bMXvV+3Bm7saTOc40uLDOT9fZZQaYBgm87Cg90OsHrpKaYHHdruaix4IRxEKx+ehy9WjgJa/DgAB3bKxRvpPrD2EfQ2dWLr2EBiGyQ5Y0Pshsu+oHWfUDLLdLidOAemha4IeDEcNvzyoTKY6dEWXjTUCYbOge1yOuM8wDJNZWND7OdWKUAPA/HGVcceU5LlMNk0gHDEEPSpiHY/UfHVZMkBG9q2+EN7YWW9Ud/Tqgm4VeoZhMgcLen9Ed0bKCz145svzTbscDsLOuy8wbass8sKpTJz6Q1GEwjF7pa7dDwCGDQNoZQD+8uZew1dv6gzisw+twUd+tgpATNBD3Zgs3dfQyQ8AhulDWND7IbLWykcnVWNYWX7cfmmHSCqLvKYSAG/sqkcwEhPWOr3phRqht3SFcPfybVj2wREAQGNn0HROt7N7lktLVxDn/HwVfrBsS1rHMwzTfVjQ+yELJ2iVKv977ui0jh9U6Db57g++sdckxMfb9Ag9SbRd1xYwXr+1q8HIX09X0Jv0B8K7e5vSOp5hmO6TVi0XJrsYVpaP/fdcmPbxBR6X4Yk7HYRIVKCxI4iKQg8aO4Ooaw8gqpQDsENtQP0/f33PeG1XJwbQbJxfvrQTP7xkCrwup1GCwK7yI8MwvQP/7xoA5Lkd+P7Fk3Hq0BL89L+mAdAEuqzAjQKPE/e8sB3XPLzGWD1qR2NHwHZ7wKZWDAD8ZPk2LF17CC9vPQ4A6AhoE69WO4hhmN6D/3flKOOri4zXXpcTs0YNwgu3LMQovbNRbbMPbqcD155VAwB4c1cD/ElazzVZPHRJoghdWjIyzb3dr3VYYkFnmL6D/3flKMu/ugDnnVoNAMhTSgXINMeOQBgelwPfWjwJv7h8BgBgZ117wvOFE5TZTeWhy08ZETpbLgzTZ/D/rhzF63IaXYzy3LF/5mqldnq+LvSnDCkGoGW2dJdEEbqKEAIbDrYA4AidYfoSnhTNYWRUrUboRV4XCj1OdAYjGFKqifuYysKE5/j55TOw5UgrHn57v+3+DQdbcKCxE6MrtHNc8cfVKMl3GdcUQuDFD4/hkXe0z3tZ0Bmmz+D/XTmMrJCYZxHRkeWajy47HRV4nHDpeerzx1fgv2YNBwDUVBTgstNHoMib/Ln/zX9tQjQqEIpEsWZ/E17ZVmfsC4SjaEgwocowTO/CEXoOE47ER+gAUJKnVWQcrAs6EaEk342mziBGlRdilC74cvFQsuqOABCORnHDo+vxyrbjxjbpnQdCEVQUxcoTpGPRMAzTMzhCz2HsLBcA8Oqe+mDFTy/Wm2QMKnAjX9/vkoLuTi7oUQGTmKv4QhHTgiUu5sUwfQcLeg4TjuqWi9v8zywjdLeyelQuPBpU4MHsmnKMry7CxTOGAkgu6EtmDMPGQy0J9/uCUeObAgBTezyGYXoXtlxyGFnf3GsR5DsumoziPBcWTawytsnORWUFbkwdXopXvv4RY18yy0XNd1eRkbhfaaYxaUgxF+dimD6EI/QcJmRMipoFeUhpHu751HSTFSMFvbwwvkGG1bKROB2Eq+aMst0ne5n6ghGE9HMXeV1suTBMH8KCnsPEJkVT/zPHIvR4QU9kuTgdhKpiL+aNrYjb16kvJPKHIkZZ3qI8l2G51LX78cfX93AzaobpRVjQcxgZobvTWJ0pW9ENKojvSSotF6uwyxrrdg8MuUjJH4oYXn6h12XUfvnevz/EPS9sxwYb/33l9jo8vb425ZgZhjHDHnoOI6PudAS9otCD+vYASmyaTEshryr24mBTV9z5va74CL65S6v9omW56JaLx2WkLcrPNnWYa8Rc+vu38b6+qvRTp49IOW6GYWKwoOcwMm0xWQ9SyV+vPQOvbD2OyiJv3D4Z6Y8YlG8WdJHY0mnWI3RfKGp8vsDrNJpOl+rfBKTwA9qqUinmDMN0H7Zccpipw0sBxNIUkzG8LB/X6JUXrUwfUYbrF47Brz4907Q9WYQu2X28HUvXHILTQch3Ow0PvVT/JiC7JQGxh4AkmqAgmHpthmFipCXoRLSYiHYQ0W4iui3JcZ8iIkFEs3tviExPue9T0/HMl+ejqjg+6u4OTgfhuxdONi1EUkk26Xqk1Y9jbX4QtMJc4ahAJCqMsrpHW33Y19CJL/xtHfbUd5g+2+a3LxZ2qKkL477zPP69gX12hlFJKehE5ATwAIALAEwGcBURTbY5rhjALQDes+5jMkO+x4mZI8v6/DqJ0hpVwlFhRPLBcNRIazzWGsDDb+/DK9uO445nPjR9xhqxS3Ye18r8Ltt4JK3xPb7mIK740+q0jmWY/kw6EfocALuFEHuFEEEASwFcYnPcjwDcC8Dfi+NjsoyPTR4ct02toFiqTKoOsUT0MpL3hyLw6YLuD0UwYpDW6Hr7MXM99pYu+6YaclVruqbL7f+3GWv2cS9TJvdJR9CHAzikvK/VtxkQ0WkARgohlvfi2Jgs5MHPzsZfrzE7anIl6gVTh+CRz51hbJ8w2LyKtEBPf+wKReDTuyMFw9GEi41aukJo6gzikDIRCwDQ53i7a6NzzjuT65zwpCgROQD8EsD/pnHsDUS0jojW1dfXn+ilmQxhbVIhuxANK8vHxMHFxnZrnXVpzfiCYSNCD0ai6NTF/dHr5piOb+4KYtF9K7HwvpWm7UaE3k2B5joyTK6TjqAfBjBSeT9C3yYpBjAVwCoi2g9gLoBldhOjQogHhRCzhRCzq6qqrLuZfoK1jZyurxBCWzy07Ob5+NEnp8bVUS/waO99wZiHHgxH0RkIozTfjYUTqnDF7Fju+ZEWn9G6znQ9/e9oNwVdXlPiC0aw7Whbt87BMNlMOoK+FsAEIhpDRB4AVwJYJncKIVqFEJVCiBohRA2AdwEsEUKs65MRMxnHWuyLdEWXAjt9RBk+M3d03MpSw3KxRuiBiG0TjURVHCOWBtTp4g+ZI/SvP7kRF/zmTduHBsP0R1IKuhAiDOBmACsAbAPwpBBiCxHdRURL+nqATPaRbqNna5XGfBsPPRTRInQp9oTYIih1kVEoEsUvX9qBjkDYsE5ONEJ/Z0+jNh4WdCZHSGulqBDieQDPW7bdmeDYs098WEw247XknUsJtnra1kg+3/DQI0a0HAxH0RkMGw2tJaPKC0yrUp9eX4v7X9uNzmDESMVs7gzhnhe249bzJyRd3OR2EkIRAb+ldK8cb0cgjGrLZ7qCYVz95/dQ5HXhsS+cmfDcDJNN8NJ/ptsk9NAtxyWyXHzBWNqijNALvXoBMP0Yq8A3dmopjH6lA9KO4+3Ycbwdw8vy8Jl5NQnH63Y6EIpE4iwX+fzpDMTXaD/S4jMsH38oklauPcNkGl76z3Qba4QeyzoxH2ddQWpnuQTCmodeqE+Y3nr+RFy3YAw+PdtcmEuW43U5yNTSDtCEPRmyOFnAYrlElQh9U20L2pWVqcFw7Gbkw4Rhsh0WdKbbeJ3maHXeOK0e+gXThpi2x0fommi3dgXNEbpiuZTmu/WOSub6M1LQHQ5CMGJ+cuyp60w6XinofkvaojxLS1cQS373Nm58dL2xT21mba0I2V0C4Qh+8dIO4yHGMH0FCzrTbawR+sTBxdh/z4U4a1ylabtV0OX7Z/Ul+zNHlhlpi9JySXQNmavuIDIaZkhW723EHc98mDAvXfZOtU6Kygi9xadF5usPNBv71MVODZ0BnAiPv3cQv31tN/7w+p4TOg/DpIIFnek26Wa5WEXZ6SB4XA7squvA8LJ8fGRiFaICaPOH4yJy6zXadNF12lguAPDouwfiPHKJEaHHCbr2d6t+bvVxoF6jUY/QQ5EoHl29H2Gb6ydD1oPv5Gwapo/hSVGm2zgcqeurA7H8dBUZ+d509ji0+zWBi0QFqix12K0ZMg0dWpS883g7Vu2wX2XcFQzbNrSW9eADVsG3CLqq6GqE3qhf+2/v7Mfdy7chEhW4dv4Y2zHYIX9eXPKX6Ws4Qmf6jGSy/8lZw00lBKpLLIJuKS/QoEfJicQcALoSeNQew0OP7RdCGK3xZLu8YCSKK/642ngtaewM4qG39hk1ZRq66ak7jdozLOhM38IROtNnVCeonw4ARV4XPEonpepi87HWejEyQk9GIkF32Xjo/lDUsFyknQMAa/Y34Vcv78T46lhhsb31nXjwjb0YVpoXd550cOoRepgjdKaPYUFn+ozhZfl457Zz8eHhVoyu0Ap1rb79XGNyVBXtwSki9ERirdIZjHnUde1+NHUGMWlIieKhx6LuLuXYFp854v7Nq7vw88tnGO9lOqOM2rtb5Mvp0K6frAMTw/QGLOhMj1k0MXWBtWFl+RhWlm+8H1oae602r7ZG6MlWfiaiS1kg9JH7VsEXimD/PRca1o8aWYeU1Me6tvjo/1irD4CWSy+9funBB8Ldi9DllIPVQ2/W89sHFXq6dT6GSQQLOtMj9v30E7aTnt1BRujFXlfcZKY1Qk9Evttp5LQ/vuYgzhpXAYeDjG0AEDFWhMaicjWLZVedufUdABxo1PzyIq/LKN7Vrv/d3QhdWi0Ri4f+7ac3IRSJ4uHPzbH7GMN0G54UZXrEiYo5EIvQq0rie56mK+ijKwrw989rgrh881E8+8HhuGOk1dGgrPiUgj66osD2vLKOjCroku566PJa1gi9oSOAwy2+bp2LYZLBgs5kDBmhDy6OnzxVLZdkee9EhFOGxJpqdPjN4huJCiNCXr7pKFZsOQYgFjVPGVZie15D0PNcppIAQPcjdCnoVgs9GIkaGTYM0xuwoDMZQwq1NWURMC9Ksi5QUukMmHPPrfnr/lDENBl546PrEY0KI898xCD7CP1oq9Yat8jrMvntABK2zEuE/Lx1UjQUFmjxhbrVeakjEMYfVu1JOsHa7g9lbBFTrteW7+63s5MNCzqTMWSEXl0cL+hqVG4tIaDSFQyjQNlvrZfiD0XivOtNh1uNCD3ZuZ0Osq2ymE7GjYp8AFhXuAYjWj/VRCtc7fjx8q2498XteHnb8YTHTPvBSzj97pe7Ncbe4NVtxzH1+yvw/sHm1Af3Q3bXtWPSHS/i2Y3xtl62wILOZAzpoVszXADzalS71Z+SzkAELkX81ZxyAPBZInQAeGr9IRzVvWtrDRkVj9Nha/dYLZhUyHTHl7Yex4aD8fViZNpkKBJNGa03d2rXDkeSH9edhwQAvLOnAXXt/m59xspqvWHI+v25KejbjmpVPV/amvhhmmlY0JmMUagL9ZDSxAuQAK1kLhBboKPis3wFbrd85X9y7SHsbTBXY3zs3YO46R/vA4hVgFSRZX/dTopb4ATY109PhlpM7Pq/xzozSqFv6QqhpSuICd99AQ++sTfpueS3DbufxYlw9Z/fw2V/WH1C55A/q+6mdfYXYr1zs3c9AQs6k+HKgYAAACAASURBVDHGVxfh/qtm4WNTBic9TmbUqNbM4inmUr1S9B98Yy92KvXR739tNwAtZ/66BfH1V6wR+g+XTEGNvgjK43La5sMfa/Pj209tMmWtrNnXlLBol2q1qEJsROhdIdS1a7nw/1pfa3sOify24epFQZfnVDtE9QT5s+ruHEN/QbZHzGI9Z0FnMgcRYcmMYWkvIpKCPrqiAL//79NM+3b/5BPG66/8c0PcZwcXe3HHRZPjLJR8tzlCdzsdhm/uSRChA8AT6w7he89sxpLfvYX1B5pxxZ9W4/5Xd9keq9ZvL1GqSkrha/UFE7bxsyK9/+5E6MFw1CgwZkco2jsCHIvQc1PQHf2gJg8LOpPVTB9Raryu0r32YDgKh4OQ73biprPHxX0mL0nFRet/RmuE7nE5DMvF43IkzYd/fM0hbKptRb0eXW89at85KWGEHjEXBwPi2/hZifbAcvnq4xtw+t2vJNxvzeLpKd4Egt7UGURbN+cdshFK0Jkrm+CVokzWsv1Hi+F0EBb/+g0AsfRGGdlu+9Fi289VFcUvpZdt8qwZLwUW8Xc7yVRrJlGErvLFx7RORxE90t1b34HRFYWG6KqC3tARxMHGLuyubzcsmxZfKKWQS+RkqKMbC7te1HPvI1Fh+yCwNgzpKYki9JseW4+hpXn49ZWzeuU6mYKMCD2z40gGR+hM1pLndlrqveiCnsCrLtdrothNWkohs0ZX1klRr8thZNW4E2S5JGLljno8tb4W5/7idfzq5Z3G9lAkignVRfjquePR0BHAhfe/ic8/EpscbekK2TbtsCOSoIxAOiS6RrrXToUUdKuHvreh05gj6M/Eeudmr6KzoDP9hqpic4Ru5aVbFwHQWtJZSRTRxkfoioeewnKx4xv/+gAAsGpnnbEtGBZwOx0YPkgrTGbNxGnpCsbSEFNohazh3pPKjQkFvbdCTv006gM3EhVo7AjEZSP1R6SQZ6+cs6Az/QiZr54oQq8s8qJCj9InDzUv6U+UFWJdOORxOWKWizM9y8WO2mYf2v0hHGjsxCvbjsPtJFwyc3jcAwTQInQp1KnEQup+T2qrJ/LKpeVyouV55LeGgCLejZ0BREX38+KzETl/wZOiDNMLyAg92f8nKcBjKgtN26Xl8vXzJ5q2uy2WihqhVxV74wS92JvetFNLVwiff2QtbnxU89cbOoLIcztxycxhcce+uOUYlq45BCD113np06spk1uOtKa1JD2V5ULQCoZ1x1KIRAU2HmoxjUl94MrSxNm+ZD4d5EOUPXSGOQHk/x8Z3V44bWjCY6VAl+Sbm07Lladf/egEvH/H+crx5rBUzXKpLs6LE/SyQvN57coWSNbubzaabsiOS3arYoHU+ecSqZWRqMBnH1qDe17Yjgvvfwtff3IjALMVY7VlEllVQaV42Oy7X8Fj7x5IaywA8MfX9+CTD7yNdfubjMhV7d0qM4ByQtD1bzjsoTPMCTC+SmsHl+92YsMd5+NXn56Z8FgpwAUeJ+aOLTe2OxU/IU8p9hUXoTscRiRWUeQxJkWJNAtmUIE5g6aswCzwKmMrC40ce5n5UWGTgaOS0nKREboQeGNnPf74+h4AwFu7GgCYc8qt+eWJrCprGYE39XOlw976TuNv2whdLyeQE4IelYKe4YEkgQWdyXp+ccUMPHTtbIwsL8CgQk9SX1sKtNflwGPXnYnzTtVWoarpennKQiaroBMBbT4tqi7Jd5uqNxbluUwLgwCgrCBeoEeW56OyyANQfF136/WspBILo1mGRazlpKMqztaIPN0sF3c35g2K8zQLqj0QNgRdXfovLZdcmBSNGPMc2avoLOhM1lOc58a5k5KXB5DIyU+vywmX04HJNvXO1cJf1rxsTdC1RTAleS6jkmOhx4VzJ1XjY1MG46o5I43jy/LjI/SRgwqweOoQtHSFjPZ16j6VHy6ZgivPiJ0vlVhI0bRG1XLCUxXnOEEP25/bGrl7Uzx0DjR24vb/24xwJIoifU6hMxA2LBf1unWG5ZK68Fi2Y3joWTy/m5agE9FiItpBRLuJ6Dab/V8kos1EtJGI3iKiyb0/VIZJjRREWUNdCry1W1AiCITTRg8CAJw6tAQLJlTi24sn4eeXz8DPL5+Bz86rwU8vnY4Z+gpWO8ulwONEeYEHTZ1BHGzqQnmhB//8wpkAgAUTKvH49XMxqlwT9gnVRbh89si4cyTCyENPcD9qJkswEjULfMII3Xwu9RtQRyAcV2zrq0s34vE1B7HtaDsKdUHvCIQNf1/NaFErOErb6e+r9+Ocn6+yHUs2EzEmRbP3wZRS0InICeABABcAmAzgKhvB/qcQYpoQYiaA+wD8stdHyjBpIKMnaXXICDzdhTgl+S587qwavHPbuZg4uBh5enmBxVPNxcCKdeulyBsv6Hlup8mKuekj43DW+Erj/bxxFcYEr9uS655qmFEbn1olrHroYWFqdNHqC6LmtuV4fM1B82cs51LbC079/gp8+k/vmva3699giGLzER1KhK5eU11QJH30O5/dgn2WCphCCPx8xQ7srrMvn5ANhCK54aHPAbBbCLFXCBEEsBTAJeoBQog25W0hsjv3nslhpKjIyUhjyX8aEfq/v3QWRgwqgMNBGFaWn/RYaTWo3ZQunK5l3xR4nCYr5/LZI+I+L715B5FpklaSKBVRfu1P1GTD5KFHIqYOQnJ16u9XaRUoo1GBNn/8KlVf0GwTybREiczc6QpGjJ9rp+Khq9eUHjoQn4uuPkiau0L43crduPrP79neVzaQKx76cACHlPe1+jYTRPRlItoDLUL/qt2JiOgGIlpHROvq6+t7Ml6GSYqMnmTU2x3LZdaoQWlfp0ifDFRLA8hr5rudmDpc8+6fvHGe7cRpnlI7XK02KYQWyV54/1smW+IHy7bgjmc+NB5YdoIuhMDHfvWG8T4Qtu9ZKr30+1/bhek/eCluWX6nfu5Eq1HltTsDYeMB02maFI0azTrqOwJGaqd1YnT8d1/Aplrzw6K3yhD0BQMqD10I8YAQYhyAbwP4XoJjHhRCzBZCzK6qquqtSzOMgdVDd3TTQ08Xmd1h6n2qC3O+x4XTR5dj590XYM6YctvPT9IbWxd4XHGZMLIy4dFWP5o7tW5Gj7yzH4++e8AQFWsUDWiWgCqaoYhAq89G0HXR/PcGrZVag1XQ9Qi70+Ya6/Y3GRO9HYGwEWW3+8Mmb7ndH0YgrLXYkw1M7L5xPPLOfgCxf58s1kpEIjngoQM4DECdtRmhb0vEUgCfPJFBMUxPiRoRuiauMkLv7f+EcsWoGqHLa6nVGhPxnQtPxV+vmY2ZI8vi6sGrxcWsoip7ptqlAVobNAfDUTR3BeOOk/67XPJvreUiI3Q1Q+czf30P7+xpwHV/ixUV6wrGIvRWX8j00GzzhYzrlOqZQHZjfldvWxfO5tQRnVA/iNDTWce8FsAEIhoDTcivBHC1egARTRBCyOr+FwKwr/TPMH2MMDx0c4Tek9onyZCTomqeupx4tavXYsXrcuKjeo68GuULIdChCKnVd5aZInaWy+bDrab3mqAnjtBl441Oy4OgKxCLwCVv7mrA1iNtKM13G1F/RyDmoTd1Bk0Tz62+kGFLydx9uwhd2j3hfjDhKD30RJ2psoGUEboQIgzgZgArAGwD8KQQYgsR3UVES/TDbiaiLUS0EcDXAVzTZyNmmCRYPXS5QtTqB8tSuz1FipXX6cALtyzEy7cuMq5h12AjGWqUL2AW0iv+tBpHW31xn/HZCPo7e8wrPIORCFptInQpnsGw9MLN55IPi21H20zbG/U0TJmy2RkIG5kfjZ1Bw5IANNtI5qOX5Gs/q4BNgS75oI2twsweRX96fS1qbltuPIjkGLPZ50+r0pAQ4nkAz1u23am8vqWXx8UwPULKgYycpVZaPfS3vn3OCXXqUbNcTtUrO8pruLvZ71Nd6BSJCpOgN3UG8fuVe+I+Yxehv7e3yfQ+ELKP0GPCZB+hdwTCaOgI4JalG23HO3dcBbYda0dnMGw8xCJRgabO2MOjzReOCXpeYstFflZGvdkj58CPn98GQLOe8txO44HVWx2e+gJeKcrkFFGL5eJ0aH/HdypyGd5uUZoVFFWKbbJc5DUcJ9DAORSJxgmsnf//+k5zlti4qkLsruswbWvsDKKlK5Tw/qTHbfXefcFI3BhUKgo9KPK6TBE6ABxXFhG1Kh66vH4wbL9atM0XykqR7NLnL+REu3wQZnMTbG5Bx+QUUi88hqBr75NlubzxrXPQ3s2el7JIV6EilvLazhMoLB6KiLgGGOl8xR9fXYQ99ebFOnVtfrR0BVFd7I0T7RsfXWebNw5oQp8ozx3Q6tEUeJzoDERQ5I3d67FWPzwuB4LhKNoVy0U+/ILhqG0D6RZfKG5S9J/vHcTcseUYqxdmywRy/kJaVHKM2Wy5cITO5BQymnXrkbnHqVsvSUS2vNCD0RWFCffbMX1EKf70mdMxX1kBKgWyOw2crQRtInRr3RY7xtkI37E2P9oDYdv5ghVbjhuvu2zSE9ts0h0BTZyvmjMKRV6XlraoPCjr2gJG9k9nIGyIt5xADoQjcQ8PAGjuCsYidKH56N/592Z84v43E93uSUX+/COKh/7SlmNYdN9KfGBZdGXl16/sxPsHm/t8jBIWdCankFGy1O+PTRmM6xeOwfcu6t3yQkSEj08ZYhJv+R/+RC0X67eFRMv8VayC7nU5cKwtAF8wYkzgJkKdFJVWlV3+OgDcdPY45LmdKPA44QtGEI5EjZ9BeyAMp4O06D0YMSJZef1AOP5hBQCtXSGThy4fEnZdjn6wbAue33w06f30NuGoOVIPRQTufXE7DjZ1YcuRtmQfxa9f2YVLf/9On49RwoLO5BTfWnwKnA4yuhu5nQ5898LJJ5zVkg6X6Uv8Z40s6/E5hIiV75WkE6HLfqXq+7o2P3yhSMo0SjVqltG0FPQRlvMW6k2189xO+ENa2qLq0TsdhELdX7daLoGwvZXT3BWMLSwSIuH9+kMRPPLOfnzpH+8nvR/JptoWHG/zx22/4k+r8U2992s6hKPmCF19wAbDia2pTGTssKAzOcUlM4djz08+Edcr9GRwzinV2H/PhRhZXpD64CQcb/ObWt1Zqx3aYa3TXlXkxbE2P3zBSMqfhRqNl+jiK7dZJ1Tlw8HrcmhL/C2C7iBCkdeFTbWt+OxDa0znSCTo9e0B0+Ima2MOQMv2mXTHi0nvw8qS372N83/5etz2Nfua0u4QBcQ8cznGcCRq1AhK9u0pExO9LOgMk2W8tbsBpyp13Nv8iTNOJIVep+W9C62+ELqCYWPlquTsU6pw2wWTMMWmVryMpqWHXmyxa6Q4xyL0KPI9TsPi0iJ0J7YqOexelxMelwOBcCQuf74kz4XaZp/ZcrERQtnCTztf+rKV6md3vM2POpsoXiXmocda9cm5mmSinYnVryzoDJNldAUj+NjkWEMPNb87EapozxhRirljyyGEVsWwwOPEzy6bbuz/3dWn4YsfGYelN8yNO4+0XFoMQTdH/gUy/15G6BEBl4OMLlBOBxm2jMSjlwgOhKJxE7AjywtwqLnLEMZgOIq7/rMlblyq9z64xL4vq4qa1fTmrvqEaZjffGoTvv30pqTnsnroQEzI7bJ2Yp9TKl+epFRHFnSGyQImVJsnNU8fHav8eLjZh1SZkGoJgp9dPsPU+zTf7TQ10ZCNse1qzRSnsFwKdcslz+3EwaYuvLz1OFxOQr4nJujWz7idBK/LiWAkGre4aOSgAhxq6oqJZlTgmY1HjP1y4ZI6cZuqLytgztz5zF/X4BsJPPPmziCOtwXitqs214+e26Y38IgJtLyPZEKtPgCOtPjQ0BHA3c9t7dP+qizoDJMFvPi1RXj2y/ON99VKFBqMRFFZ5E36eTVCdzsdxqIpIL4UgVwM5bFpNSfF+FldVK0ZMoWK5SJxORxGOWAnkSk3HzBH6FbLZWR5PmqbfQlzu2XlyY6A9reDgA0HW7ByR53t8RKrV58oGyUYjtpm9Kjj3HioBb99bZcp4pb7kwt6bN+a/U247enN+Mtb+7BaL0jWF7CgM0wW4HSQKROn0hKFDi2NtxlW336u8VpG3fK1WoO9wOKhy45EamciWbPcmhFjjbblg8PUZQkxgXc44gXd63TC63Lg6fdr8dvXdpv2DSvLRyAcRUO7va3U7g9jx7F2fPExLbNl0hDN9//cw2ttj5dYBd3w6C2ZJ8FI1Dbn3irUtU0+U2QtvwEEI4mjbXWi953dDVi7XyvNcLQ1uWd/IrCgM0yWoGaqWEvqDi7JM1IxJapwquLssUTo+WkUC5MPkwKrGFtsGZlzrlo8wXDUEHSnAyiyTNB6XA5AH97hFnOhseriPNvtxrkjUfzlzb3G+3TsFiC+Pk0wgecdCEXQbrFT7I5bvvko3tsXq5UjDw+FBbqCYdTcthxPrjtk+oxarKy22WfYNAcazSt6exMWdIbJEqz2hpqFMrQ0D/+5eQH+oTebBhJne7idDlPz6nRSOKWlY43mXY7YNW46e5yRl65eOxSJGm30nEQosJkU9ScoJTC4RLtuQkEPRzHI9M0lufUksXr10qO3VnyUaYc9WcwFaF778k3aQqffWb59qOmX7f5YXr61n2pvwrVcGCZLsJYMWP7VhZj2/RVoD4RRVuDBkNI8o/sPoEXiL35tYVybObfLYYrKrQJrh7RarNG8S7Fyvr14kvE6L0GE7nAQKi3fJJwOSlhpUWasHG5OLOjqw6kkxapXSaLyCdacfhmJt/nCJpsq3ayUZzYeMSZxDzZ14Xib37gneU0HAfVK2mWih1dvwBE6w2QxMt/ZrpE0EWHSkBLMHVth2u52kklwrXnoya5jFX/pzVuzbNTxBMNR4xpOIkwbXhp3flXQVb9f2khHbGq+A1r0r/r4qtWTbCXmqh3mapQy4k7UMMQ6MZpI0O0mklXO/Mmrxms50Vuc5zalniYrfHaicITOMFnEf25egEGFsYhUZlZYPfVkuB1m0cn3pI7bpIdsnRSVlou1uJk6nmDEHKHLfqkqqpCW5LnRqAtcntuJ0ny3bTNrQBNWNf0vT7F6Aso3A8kLm48iz+00epVK5KSoGqELIQzhtgp6ovzyiiJP2pOa8mdanOcyzl9e6LEtUNZbcITOMFnEtBGlGDEoVjrAWt89HWRxsDGVWgVJSpLEPrwsH7NHDzIeHFbLRUbTDss5rBG6V/HQ89xOLJxQiUSoE7YAUFORuFRCMBI1rbhUc+et+dxCCNz0j/fxuUfiM2DkJKb6YAlZOiwBwKGmLkSjImGE3p2aQHLc6uKsISV5Rou/voAFnWGyGCm0PalN88MlU+BxOjBGLw383FcW4AnL6tC3bzsXT910luH7qumSq75xNly6xWB9JiSK0OU8wKPXnYlEFFsEfWaSYmZBfTUqAFx62nDTPqsvn2zVJqAJvhqhqxOfrb4Qjrf5sfC+lbh3xfaE6YjpCHowHMVvX92FR1cfAGAunzCkNA9doUhcS8TeggWdYbIYa4/U7rBoYhV2/vgCI0tk6vBSnGnx2yU/XDIFv7xiBk4fXW5sq6kshEsXaGtNF9VKVj10tXTwm986B//+0llx1xpUYBH0UYkFXauVrgnvzy+bYVrc0xmI4JkNhw07JVmXJUATfFX0A8oDoc0XMjJdlm86ekIR+vE2P37x8k5jslSdyB1c4oUQgD+Ngms9gT10hukH9ETQu0Oh14VLTxthvJfWhltXbquQWbP6YmmLsW0jywuMypNLZgzDsg80gbMukrJrziH59tObUVXshdNBcDjIlC/+99X78ffVB9DSFcS188fENbu2EghFTTaNNUIPhrVzt3SFEnvohanTJo9Zin2ZLRct7bMjEE4r+6i7cITOMP0A1XI579RqzLCxKZJZF93h8evnYuU3zgYQS1tUa8MAscqDklhXInsh/M2VM3H9wjEA4otrWRdMWalvDxhevhqh7zzeDkATx3+tOxQ3EWq1aGbc9ZKpw5DaVLvNHzIsnA6llruVdBY2dVgqPJotF+1eu1I8fHoKR+gM0w9QI/S/XHOG7TFP3jivV/pdzhsXs2VkRGwVMnXiFgDKdF+8PUG5WiIy0vWs0X46Ua/8pqDWR2ns0DJlCjwufPMpc8VEB8VPvgLA/crin689sdF43eoLJ4zeVawPNjusWSyqoMtc906btn+9AUfoDNMP8KYxKepxOeLqqJwoMp3QKsJTh5caUXxVsddY/JOs2basTV6S58btF0wyyvfaVX20IgVd9fhl6qNdT1SB1DnjKq2+kKkglzVCn6X7/Grd+UTjrm83V29ULRdZWjiVPdRTOEJnmH5AX3voiZCRpKy5ojKmshBLb5iLmopCYzl7oggdAEaVa/7xqIoCfHLW8ITH2SEtl8VTh+Cf15+Jq//8nrFY55Vt8ZUXhTCvck2Gg7RJUZ+p+JZZcGW0ry5yKvQ4ba2Zh9/ZZ3ovI3Svy2E8EPoqQmdBZ5h+QCZa6gHAZ+fVoK4tgC/o/rcVuUq1uUsT12SCfstHJ2L++EqcNmpQwmMSodaUGWmxezYeakFVsTcuMnanGaGXF3rjBN16Hz+7bAb+7/1azFLGXuBxodlmQdShJvOqVxmhVxZ5jW9QfeWhs+XCMP2ATEXoRV4XfrBkSsqMDGm5JCtq5XE5cNY4+wVHF88YlvT8qr1h93C7bkHsgXP1maNw63kTDUFXSx84HYSR5ebG11XFXrT5QyYPvd0fMuXeVxV7ceNHxpnKFljb/iVCrrKtLPIYK3HZQ2eYAUymBD1dyvLTX0Fpx2+vmoUVX1uUcL9LyW8vzXfHFelS5w7uWjIFt5w3wRBfNe99610fx1VzRpk+W1XsRUNHEHc+G2t919wVtPXg1ajfOjGciJpK7bgvLByL4jw3po8oNTUB702y+7eEYRgA6U2KZhK74mHdxVo+WMWlCKnH5cBPLp1mirzVGi/yWCm+ahVFj9NhejgAQJVNSd7nNx+zTcFUBX1cVWHC8aoML8vH/nsuxMUzhqE0341lNy/ABdOGpvXZ7pLWvwIRLSaiHUS0m4hus9n/dSLaSkSbiOhVIhrd+0NlmIFLXpZH6LJejF2lxXSxdkdSCVusnIumD8O2Hy023ud7nPj75+fg5nPGG9tkGQI1Q4eI4LQUL0uVB6+iljgem2RBVKLP9DUpf0uIyAngAQAXAJgM4Coimmw5bAOA2UKI6QCeAnBfbw+UYQYyrm6k4GWKdd87D0/cODf1gQkoTNJZKVXDiXy3E4smVuEbHz8l9hk9wi6zlBqwRuinDElPmK3UVJgjdLUl4Bk1scnTdCdne4N0rjQHwG4hxF4hRBDAUgCXqAcIIVYKIbr0t+8CGAGGYQYUlUXeE1rOnuyhlarhhF3Nd5l6aF0MZI2Yk3VBGlKSh/NOrbbdV+BxYlR5zEdXC5ZdMDVmqVgfIH1JOoI+HIDaLK9W35aI6wC8YLeDiG4gonVEtK6+vt7uEIZhmDhSCXqeTXQfE/TkEbrdilIA+ObHT8G73/lo3Mpc+U3C5SS88a1zjO3qg0K1cU6m5dKrU61E9D8AZgP4iN1+IcSDAB4EgNmzZ/dN/UiGySGeuGEuth5ty/QwMk6q0rh2EbpMQyxNEqH/4wtnmppzq3x2nv1U4ORhJVi7vzmu+5Ga0qhG/cnq0fc26UTohwGMVN6P0LeZIKLzAHwXwBIhRMC6n2GY7nPm2Ap8br79op5c5PsXW6fnNNLx0K2cP3kwAGDBeHPuu1xBumhiFeaPrzRF6FfNiUldosVc9181C1fNGRk3AawufrKWGz5ZpHPVtQAmENEYaEJ+JYCr1QOIaBaAPwFYLISIX4fLMAyTBp+bPwZnjavEvoZOEAEHG7vw4+e3pfbQbSyX+eMrsf+eC+O2O422etp7VXyvPWsMHl+jOcyJJjOHlubjp5dOj9uuWjnjq3s20XqipBR0IUSYiG4GsAKAE8BDQogtRHQXgHVCiGUAfgagCMC/9K8XB4UQS/pw3AzD5CinDCnGKXpf0qOtPvz4+W0pP9Od0ghuXXil9SInY0cMyk+rUFgiHA7Cc19ZgCMtvoyVakjre4EQ4nkAz1u23am8Pq+Xx8UwDJN29ch0FjZ5LO301D6py7+6AENK8uBP8U0gFVOHl2KqbsW8/s2zsb+xK8UnehcuzsUwTNZSmGYaZKpSuSu/cbZhrUg7Xp0cnTJME2Frga8TYXRFIUZXpLeatLdgQWcYJmuRopsq8y9VJsmYypiwhvVuSw6bk56I5ZINsKAzDJPV/O7qWZg0pKTXzhfVO287bR4C2V4ELRX9e/QMw+Q8F00fljBrZMmMYab873Sws1wk3elylI1whM4wTL/l/qtmAZjVrc9E9T6pDpsI3c6G6U/078cRwzBMN4nolsvJrLFysmBBZxhmQCFXeJ4zyb7oVn+GLReGYQYUU4eXYutdHz+hypDZSu7dEcMwTAqSifm9n5qWdvMKAHjhloXoCPRNj9DuwoLOMAyj8OkzRqU+SOHUob2XUnmisIfOMAyTI7CgMwzD5Ags6AzDMDkCCzrDMEyOwILOMAyTI7CgMwzD5Ags6AzDMDkCCzrDMEyOQEIvVHPSL0xUD+BADz9eCaChF4fTH+B7HhjwPQ8MTuSeRwshqux2ZEzQTwQiWieEmJ3pcZxM+J4HBnzPA4O+ume2XBiGYXIEFnSGYZgcob8K+oOZHkAG4HseGPA9Dwz65J77pYfOMAzDxNNfI3SGYRjGAgs6wzBMjtDvBJ2IFhPRDiLaTUS3ZXo8vQURPUREdUT0obKtnIheJqJd+t+D9O1ERPfrP4NNRHRa5kbec4hoJBGtJKKtRLSFiG7Rt+fsfRNRHhGtIaIP9Hv+ob59DBG9p9/bE0Tk0bd79fe79f01mRx/TyEiJxFtIKLn9Pc5fb8AQET7iWgzEW0konX6tj793e5Xgk5ETgAP1T5ppQAAAzFJREFUALgAwGQAVxHR5MyOqtd4BMBiy7bbALwqhJgA4FX9PaDd/wT9zw0A/nCSxtjbhAH8rxBiMoC5AL6s/3vm8n0HAJwrhJgBYCaAxUQ0F8C9AH4lhBgPoBnAdfrx1wFo1rf/Sj+uP3ILgG3K+1y/X8k5QoiZSs553/5uCyH6zR8A8wCsUN7fDuD2TI+rF++vBsCHyvsdAIbqr4cC2KG//hOAq+yO689/ADwL4PyBct8ACgC8D+BMaKsGXfp24/ccwAoA8/TXLv04yvTYu3mfI3TxOhfAcwAol+9Xue/9ACot2/r0d7tfRegAhgM4pLyv1bflKoOFEEf118cADNZf59zPQf9qPQvAe8jx+9bth40A6gC8DGAPgBYhhOw0rN6Xcc/6/lYAFSd3xCfMrwF8C0BUf1+B3L5fiQDwEhGtJ6Ib9G19+rvNTaL7CUIIQUQ5mWNKREUAngbwNSFEGxEZ+3LxvoUQEQAziagMwL8BTMrwkPoMIroIQJ0QYj0RnZ3p8ZxkFgghDhNRNYCXiWi7urMvfrf7W4R+GMBI5f0IfVuucpyIhgKA/nedvj1nfg5E5IYm5v8QQvyfvjnn7xsAhBAtAFZCsxzKiEgGWOp9Gfes7y8F0HiSh3oizAewhIj2A1gKzXb5DXL3fg2EEIf1v+ugPbjnoI9/t/uboK8FMEGfIfcAuBLAsgyPqS9ZBuAa/fU10Dxmuf2z+sz4XACtyte4fgNpofhfAWwTQvxS2ZWz901EVXpkDiLKhzZnsA2asF+mH2a9Z/mzuAzAa0I3WfsDQojbhRAjhBA10P6/viaE+G/k6P1KiKiQiIrlawAfA/Ah+vp3O9MTBz2YaPgEgJ3QfMfvZno8vXhfjwM4CiAEzT+7Dpp3+CqAXQBeAVCuH0vQsn32ANgMYHamx9/De14AzWfcBGCj/ucTuXzfAKYD2KDf84cA7tS3jwWwBsBuAP8C4NW35+nvd+v7x2b6Hk7g3s8G8NxAuF/9/j7Q/2yRWtXXv9u89J9hGCZH6G+WC8MwDJMAFnSGYZgcgQWdYRgmR2BBZxiGyRFY0BmGYXIEFnSGYZgcgQWdYRgmR/h/V8+egw98lv4AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp8d-0N7JPlR"
      },
      "source": [
        "### With Glove embeddings: \n",
        "\n",
        "Now, we would like to integrate pre-trained word embeddings into our model ! Let's use again the functions that we used in the previous lab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "RUa7xjDv0Z-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59579ed9-e7b6-40bb-cde8-5380d7a8694f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "loaded_glove_model = api.load(\"glove-wiki-gigaword-300\")\n",
        "loaded_glove_embeddings = loaded_glove_model.vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "unwB2-4r0aBg"
      },
      "outputs": [],
      "source": [
        "def get_glove_adapted_embeddings(glove_model, input_voc):\n",
        "    keys = {i: glove_model.key_to_index.get(w, None) for w, i in input_voc.items()}\n",
        "    index_dict = {i: key for i, key in keys.items() if key is not None}\n",
        "    embeddings = np.zeros((len(input_voc)+1,glove_model.vectors.shape[1]))\n",
        "    for i, ind in index_dict.items():\n",
        "        embeddings[i] = glove_model.vectors[ind]\n",
        "    return embeddings\n",
        "\n",
        "GloveEmbeddings = get_glove_adapted_embeddings(loaded_glove_model, training_word2idx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.FloatTensor(GloveEmbeddings)"
      ],
      "metadata": {
        "id": "5mgTDvArH076"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "dhoS6NH20aEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662f132b-03d7-4791-bede-6c64cc8bec25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24040, 300)\n",
            "[ 4.65600006e-02  2.13180006e-01 -7.43639981e-03 -4.58539993e-01\n",
            " -3.56389992e-02  2.36430004e-01 -2.88360000e-01  2.15210006e-01\n",
            " -1.34859994e-01 -1.64129996e+00 -2.60910004e-01  3.24340016e-02\n",
            "  5.66210002e-02 -4.32960019e-02 -2.16719992e-02  2.24759996e-01\n",
            " -7.51290023e-02 -6.70180023e-02 -1.42470002e-01  3.88250016e-02\n",
            " -1.89510003e-01  2.99769998e-01  3.93049985e-01  1.78870007e-01\n",
            " -1.73429996e-01 -2.11779997e-01  2.36169994e-01 -6.36809990e-02\n",
            " -4.23180014e-01 -1.16609998e-01  9.37540010e-02  1.72959998e-01\n",
            " -3.30729991e-01  4.91120011e-01 -6.89949989e-01 -9.24620032e-02\n",
            "  2.47419998e-01 -1.79910004e-01  9.79079977e-02  8.31179991e-02\n",
            "  1.52989998e-01 -2.72760004e-01 -3.89339998e-02  5.44529974e-01\n",
            "  5.37370026e-01  2.91049987e-01 -7.35139987e-03  4.78800014e-02\n",
            " -4.07599986e-01 -2.67590005e-02  1.79189995e-01  1.09770000e-02\n",
            " -1.09630004e-01 -2.63949990e-01  7.39900023e-02  2.62360007e-01\n",
            " -1.50800005e-01  3.46230000e-01  2.57580012e-01  1.19709998e-01\n",
            " -3.71350013e-02 -7.15930015e-02  4.38980013e-01 -4.07640003e-02\n",
            "  1.64250005e-02 -4.46399987e-01  1.71969995e-01  4.62459996e-02\n",
            "  5.86390011e-02  4.14990000e-02  5.39479971e-01  5.24950027e-01\n",
            "  1.13609999e-01 -4.83149998e-02 -3.63849998e-01  1.87040001e-01\n",
            "  9.27610025e-02 -1.11290000e-01 -4.20850009e-01  1.39919996e-01\n",
            " -3.93379986e-01 -6.79450035e-02  1.21880002e-01  1.67070001e-01\n",
            "  7.51689970e-02 -1.55290002e-02 -1.94989994e-01  1.96380004e-01\n",
            "  5.31940013e-02  2.51700014e-01 -3.48450005e-01 -1.06380001e-01\n",
            " -3.46920013e-01 -1.90239996e-01 -2.00399995e-01  1.21540003e-01\n",
            " -2.92079985e-01  2.33529992e-02 -1.16180003e-01 -3.57679993e-01\n",
            "  6.23040013e-02  3.58839989e-01  2.90600006e-02  7.30049983e-03\n",
            "  4.94820019e-03 -1.50480002e-01 -1.23130001e-01  1.93370000e-01\n",
            "  1.21730000e-01  4.45030004e-01  2.51470000e-01  1.07809998e-01\n",
            " -1.77159995e-01  3.86909992e-02  8.15299973e-02  1.46669999e-01\n",
            "  6.36660010e-02  6.13319986e-02 -7.55689964e-02 -3.77240002e-01\n",
            "  1.58500001e-02 -3.03420007e-01  2.83740014e-01 -4.20130007e-02\n",
            " -4.07150015e-02 -1.52689993e-01  7.49799982e-02  1.55770004e-01\n",
            "  1.04330003e-01  3.13930005e-01  1.93090007e-01  1.94289997e-01\n",
            "  1.51850000e-01 -1.01920001e-01 -1.87849998e-02  2.07910001e-01\n",
            "  1.33660004e-01  1.90380007e-01 -2.55580008e-01  3.03999990e-01\n",
            " -1.89599991e-02  2.01470003e-01 -4.21099991e-01 -7.51559995e-03\n",
            " -2.79769987e-01 -1.93140000e-01  4.62040007e-02  1.99709997e-01\n",
            " -3.02069992e-01  2.57349998e-01  6.81070030e-01 -1.94089994e-01\n",
            "  2.39840001e-01  2.24930003e-01  6.52239978e-01 -1.35609999e-01\n",
            " -1.73830003e-01 -4.82090004e-02 -1.18600003e-01  2.15879991e-03\n",
            " -1.95250008e-02  1.19479999e-01  1.93460003e-01 -4.08199996e-01\n",
            " -8.29659998e-02  1.66260004e-01 -1.06009997e-01  3.58610004e-01\n",
            "  1.69220001e-01  7.25900009e-02 -2.48030007e-01 -1.00240000e-01\n",
            " -5.24909973e-01 -1.77450001e-01 -3.66470009e-01  2.61799991e-01\n",
            " -1.20770000e-02  8.31900015e-02 -2.15279996e-01  4.10450011e-01\n",
            "  2.91359991e-01  3.08690012e-01  7.88640007e-02  3.22070003e-01\n",
            " -4.10230011e-02 -1.09700002e-01 -9.20410007e-02 -1.23389997e-01\n",
            " -1.64159998e-01  3.53819996e-01 -8.27739984e-02  3.31710011e-01\n",
            " -2.47380003e-01 -4.89280000e-02  1.57460004e-01  1.89879999e-01\n",
            " -2.66420003e-02  6.33149967e-02 -1.06729995e-02  3.40889990e-01\n",
            "  1.41059995e+00  1.34169996e-01  2.81910002e-01 -2.59400010e-01\n",
            "  5.52669987e-02 -5.24250008e-02 -2.57889986e-01  1.91270001e-02\n",
            " -2.20839996e-02  3.21130008e-01  6.88180029e-02  5.12070000e-01\n",
            "  1.64780006e-01 -2.01940000e-01  2.92320013e-01  9.85750034e-02\n",
            "  1.31449997e-02 -1.06519997e-01  1.35100007e-01 -4.53319997e-02\n",
            "  2.06970006e-01 -4.84250009e-01 -4.47059989e-01  3.33050010e-03\n",
            "  2.92639993e-03 -1.09750003e-01 -2.33250007e-01  2.24419996e-01\n",
            " -1.05030000e-01  1.23389997e-01  1.09779999e-01  4.89940010e-02\n",
            " -2.51569986e-01  4.03189987e-01  3.53179991e-01  1.86509997e-01\n",
            " -2.36220006e-02 -1.27340004e-01  1.14749998e-01  2.73589998e-01\n",
            " -2.18659997e-01  1.57939997e-02  8.17539990e-01 -2.37920005e-02\n",
            " -8.54690015e-01 -1.62029997e-01  1.80759996e-01  2.80140005e-02\n",
            " -1.43399999e-01  1.31389999e-03 -9.17349979e-02 -8.97039995e-02\n",
            "  1.11050002e-01 -1.67030007e-01  6.83770031e-02 -8.73880014e-02\n",
            " -3.97889987e-02  1.41840000e-02  2.11870000e-01  2.85789996e-01\n",
            " -2.87970006e-01 -5.89959994e-02 -3.24359983e-02 -4.70090006e-03\n",
            " -1.70519993e-01 -3.47409993e-02 -1.14890002e-01  7.50930011e-02\n",
            "  9.95260030e-02  4.81830016e-02 -7.37750009e-02 -4.18170005e-01\n",
            "  4.12680022e-03  4.44139987e-01 -1.60620004e-01  1.42940000e-01\n",
            " -2.26279998e+00 -2.73470003e-02  8.13109994e-01  7.74169981e-01\n",
            " -2.56390005e-01 -1.15759999e-01 -1.19819999e-01 -2.13630006e-01\n",
            "  2.84289997e-02  2.72610009e-01  3.10260002e-02  9.67819989e-02\n",
            "  6.77690003e-03  1.40819997e-01 -1.30639998e-02 -2.96860009e-01\n",
            " -7.99129978e-02  1.94999993e-01  3.15489992e-02  2.85059988e-01\n",
            " -8.74610022e-02  9.06109996e-03 -2.09889993e-01  5.39130010e-02]\n"
          ]
        }
      ],
      "source": [
        "print(GloveEmbeddings.shape)\n",
        "# We should check that the \"padding\" vector is at zero\n",
        "print(GloveEmbeddings[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpkmUwA4LjT0"
      },
      "source": [
        "Here, implement a ```PretrainedAveragingModel``` very similar to the previous model, using the ```nn.Embedding``` method ```from_pretrained()``` to initialize the embeddings from a numpy array. Use the ```requires_grad_``` method to specify if the model must fine-tune the embeddings or not ! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE4ke06FbzPq"
      },
      "source": [
        "<div class='alert alert-block alert-info'>\n",
        "            Code:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "aVh4fz39Lg5c"
      },
      "outputs": [],
      "source": [
        "class PretrainedAveragingModel(nn.Module):\n",
        "    def __init__(self, weight, fine_tune=False):\n",
        "      super().__init__()\n",
        "      # Create an embedding object. Be careful to padding - you need to increase the vocabulary size by one !\n",
        "      # Look into the arguments of the nn.Embedding class\n",
        "      self.embedding = nn.Embedding.from_pretrained(weight, padding_idx=0).requires_grad_(fine_tune) \n",
        "      # Create a linear layer that will transform the mean of the embeddings into a classification score\n",
        "      self.linear = nn.Linear(self.embedding.embedding_dim, 1)\n",
        "      # No need for sigmoid, it will be into the criterion ! \n",
        "      \n",
        "    def forward(self, inputs):\n",
        "      # Remember: the inpts are written as Batch_size * seq_length * embedding_dim\n",
        "      # First, take the mean of the embeddings of the document\n",
        "      emb = self.embedding(inputs)\n",
        "      x = torch.mean(emb, dim=1)\n",
        "      # Then make it go through the linear layer and remove the extra dimension with the method .squeeze()\n",
        "      o = torch.squeeze(self.linear(x))\n",
        "      return o\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = PretrainedAveragingModel(torch.FloatTensor(GloveEmbeddings))\n",
        "# Create an optimizer\n",
        "opt = optim.Adam(model.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
        "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "train_losses = experiment(model, opt, criterion)\n",
        "\n",
        "plt.plot(train_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "id": "Ypxvfrvsuhba",
        "outputId": "e46db424-2186-4e70-dbea-8d6b79b45e96"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning training...\n",
            "Epoch 1:\n",
            "Batch 0 : training loss = 0.6945489645004272; training acc = 47.5\n",
            "Batch 20 : training loss = 0.6753852963447571; training acc = 62.0\n",
            "Batch 40 : training loss = 0.675645112991333; training acc = 58.5\n",
            "Batch 60 : training loss = 0.6568018198013306; training acc = 66.5\n",
            "Batch 80 : training loss = 0.636055588722229; training acc = 72.5\n",
            "Epoch 1 : Validation loss = 0.6416148695349694; Validation acc = 66.9\n",
            "Epoch 2:\n",
            "Batch 0 : training loss = 0.6266465187072754; training acc = 71.0\n",
            "Batch 20 : training loss = 0.6260228753089905; training acc = 71.5\n",
            "Batch 40 : training loss = 0.6151863932609558; training acc = 71.5\n",
            "Batch 60 : training loss = 0.6362295746803284; training acc = 68.0\n",
            "Batch 80 : training loss = 0.6273787021636963; training acc = 63.0\n",
            "Epoch 2 : Validation loss = 0.6151577246189117; Validation acc = 68.62\n",
            "Epoch 3:\n",
            "Batch 0 : training loss = 0.5959733724594116; training acc = 74.5\n",
            "Batch 20 : training loss = 0.628242015838623; training acc = 67.0\n",
            "Batch 40 : training loss = 0.5982662439346313; training acc = 72.0\n",
            "Batch 60 : training loss = 0.5822015404701233; training acc = 74.0\n",
            "Batch 80 : training loss = 0.5760418176651001; training acc = 75.5\n",
            "Epoch 3 : Validation loss = 0.5958750480413437; Validation acc = 70.16\n",
            "Epoch 4:\n",
            "Batch 0 : training loss = 0.587730348110199; training acc = 72.0\n",
            "Batch 20 : training loss = 0.5945287346839905; training acc = 70.0\n",
            "Batch 40 : training loss = 0.5772179961204529; training acc = 72.0\n",
            "Batch 60 : training loss = 0.55330890417099; training acc = 76.0\n",
            "Batch 80 : training loss = 0.6078231334686279; training acc = 68.5\n",
            "Epoch 4 : Validation loss = 0.5789760357141495; Validation acc = 72.04\n",
            "Epoch 5:\n",
            "Batch 0 : training loss = 0.5861573815345764; training acc = 67.5\n",
            "Batch 20 : training loss = 0.5503346920013428; training acc = 73.0\n",
            "Batch 40 : training loss = 0.5607947111129761; training acc = 74.0\n",
            "Batch 60 : training loss = 0.5525344014167786; training acc = 74.5\n",
            "Batch 80 : training loss = 0.543314516544342; training acc = 74.0\n",
            "Epoch 5 : Validation loss = 0.5666675226390362; Validation acc = 72.62\n",
            "Epoch 5 : Test loss = 0.5701956479847431; Test acc = 72.252\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f20b46375d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = PretrainedAveragingModel(torch.FloatTensor(GloveEmbeddings), fine_tune = True)\n",
        "# Create an optimizer\n",
        "opt = optim.Adam(model.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
        "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "train_losses = experiment(model, opt, criterion)\n",
        "\n",
        "plt.plot(train_losses)"
      ],
      "metadata": {
        "id": "GRGePAL2lZFV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        },
        "outputId": "d3642dcd-6425-4931-e8fc-970f636bbb59"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning training...\n",
            "Epoch 1:\n",
            "Batch 0 : training loss = 0.6983088850975037; training acc = 50.5\n",
            "Batch 20 : training loss = 0.677682638168335; training acc = 59.0\n",
            "Batch 40 : training loss = 0.6390252709388733; training acc = 73.0\n",
            "Batch 60 : training loss = 0.5825512409210205; training acc = 76.0\n",
            "Batch 80 : training loss = 0.534740686416626; training acc = 82.0\n",
            "Epoch 1 : Validation loss = 0.5216215221583843; Validation acc = 76.64\n",
            "Epoch 2:\n",
            "Batch 0 : training loss = 0.4980985224246979; training acc = 78.5\n",
            "Batch 20 : training loss = 0.4625823497772217; training acc = 83.5\n",
            "Batch 40 : training loss = 0.405974417924881; training acc = 85.0\n",
            "Batch 60 : training loss = 0.4097089469432831; training acc = 84.5\n",
            "Batch 80 : training loss = 0.38762789964675903; training acc = 84.5\n",
            "Epoch 2 : Validation loss = 0.4029174806177616; Validation acc = 82.52\n",
            "Epoch 3:\n",
            "Batch 0 : training loss = 0.3072006106376648; training acc = 91.5\n",
            "Batch 20 : training loss = 0.3115071952342987; training acc = 87.5\n",
            "Batch 40 : training loss = 0.29317137598991394; training acc = 88.0\n",
            "Batch 60 : training loss = 0.31131067872047424; training acc = 85.0\n",
            "Batch 80 : training loss = 0.3151807487010956; training acc = 86.5\n",
            "Epoch 3 : Validation loss = 0.3722654906660318; Validation acc = 83.78\n",
            "Epoch 4:\n",
            "Batch 0 : training loss = 0.2771320343017578; training acc = 87.0\n",
            "Batch 20 : training loss = 0.19620035588741302; training acc = 95.0\n",
            "Batch 40 : training loss = 0.24900779128074646; training acc = 90.5\n",
            "Batch 60 : training loss = 0.23669880628585815; training acc = 90.5\n",
            "Batch 80 : training loss = 0.24544641375541687; training acc = 90.5\n",
            "Epoch 4 : Validation loss = 0.3637134386599064; Validation acc = 84.54\n",
            "Epoch 5:\n",
            "Batch 0 : training loss = 0.20203188061714172; training acc = 92.5\n",
            "Batch 20 : training loss = 0.20856128633022308; training acc = 95.0\n",
            "Batch 40 : training loss = 0.20481185615062714; training acc = 91.5\n",
            "Batch 60 : training loss = 0.16162265837192535; training acc = 95.0\n",
            "Batch 80 : training loss = 0.22409187257289886; training acc = 92.0\n",
            "Epoch 5 : Validation loss = 0.36930089324712756; Validation acc = 84.34\n",
            "Early stopping.\n",
            "Epoch 5 : Test loss = 0.4108851628601551; Test acc = 81.656\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f20b458db10>]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmQUbBVxLtwa"
      },
      "source": [
        "<div class='alert alert-block alert-warning'>\n",
        "            Questions:</div>\n",
        "            \n",
        "- What are the results **with and without fine-tuning of embeddings imported from GloVe** ?\n",
        "- Make hypothesis based on your intuition and the class on how the size of the vocabulary (change the minimum frequency of words to be taken in the vocabular) will impact results, in the three cases (No pre-training, pre-training without fine-tuning, pretraining with fine-tuning).\n",
        "- Verify experiments and analyze your results !"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that if we set the fine-tuning parameter to False we obtain a final accuracy on testing data of 72.3%. However, if we set it to True and that we look at the performance, we can see that we obtain an accuracy of 81.6% on testing data.\n",
        "Thus, the model accuracy is improving when we fine-tune with the embedding imported from GloVe.\n",
        "\n",
        "The size of the vocabulary can have several level of importance depending on the cases :  \n",
        "1.   No pre-training : the size of the vocabulary will impact for sur the model, we completely build the embedding on this vocabulary. So, if thi one is too small, the embedding won't be able to extract the real information from the text.\n",
        "2.   Pre-training without fine-tuning : the size of the vocabulary can impact the model but less than without any pre-training. Indeed, the pre-trained word embeddings capture the semantic and syntactic meaning of a word as they are trained on large datasets. Hence, the size of the vocabulary will lightly impact the model.\n",
        "3.   Pre-training with fine-tuning : the size of the vocabulary won't or will really slightly impact the model because the model will be pretrained and the vocabulary will already be built with trained weights on large datasets.\n",
        "\n",
        "\n",
        "We can see the following results with the experiences made below ;\n",
        "\n",
        "|min_freq| NO PRETRAINING  |  PRETRAINING WITH FINETUNING         | PRETRAINING WITHOUT FINETUNING|\n",
        "|:----| :---------------: |:---------------:| -----:|\n",
        "|5| 81.5  |  61.36   | 81.5 |\n",
        "|10| 81.784  | 62.332 |   81.62 |\n",
        "|15| 81.708  | 62.12   |   81.784 |\n",
        "\n",
        "\n",
        "Nothing seems to really change, we can wonder if the counter word is really working ?"
      ],
      "metadata": {
        "id": "rdlIUGuRhx8Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "xc6i1FXsLil8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "420f0432-a642-452a-da39-6160356000cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########### NO PRETRAINING ##############\n",
            "--------MINFREQ = 5 ----------\n",
            "Beginning training...\n",
            "Epoch 1:\n",
            "Batch 0 : training loss = 0.6914109587669373; training acc = 55.0\n",
            "Batch 20 : training loss = 0.6643921732902527; training acc = 68.0\n",
            "Batch 40 : training loss = 0.6367971897125244; training acc = 69.0\n",
            "Batch 60 : training loss = 0.6204842329025269; training acc = 70.0\n",
            "Batch 80 : training loss = 0.5536143779754639; training acc = 80.5\n",
            "Epoch 1 : Validation loss = 0.5441565673053265; Validation acc = 74.52\n",
            "Epoch 2:\n",
            "Batch 0 : training loss = 0.5431444644927979; training acc = 75.5\n",
            "Batch 20 : training loss = 0.47535598278045654; training acc = 77.0\n",
            "Batch 40 : training loss = 0.3933904767036438; training acc = 86.5\n",
            "Batch 60 : training loss = 0.4303431212902069; training acc = 82.5\n",
            "Batch 80 : training loss = 0.40195176005363464; training acc = 81.0\n",
            "Epoch 2 : Validation loss = 0.4214818593114614; Validation acc = 81.3\n",
            "Epoch 3:\n",
            "Batch 0 : training loss = 0.3438987731933594; training acc = 86.5\n",
            "Batch 20 : training loss = 0.36322522163391113; training acc = 85.5\n",
            "Batch 40 : training loss = 0.3108600378036499; training acc = 86.5\n",
            "Batch 60 : training loss = 0.3125709295272827; training acc = 88.0\n",
            "Batch 80 : training loss = 0.3890009820461273; training acc = 82.5\n",
            "Epoch 3 : Validation loss = 0.3804373639822006; Validation acc = 83.4\n",
            "Epoch 4:\n",
            "Batch 0 : training loss = 0.2772101163864136; training acc = 88.5\n",
            "Batch 20 : training loss = 0.26167967915534973; training acc = 90.5\n",
            "Batch 40 : training loss = 0.27617350220680237; training acc = 90.0\n",
            "Batch 60 : training loss = 0.2846498489379883; training acc = 88.0\n",
            "Batch 80 : training loss = 0.2986786961555481; training acc = 89.0\n",
            "Epoch 4 : Validation loss = 0.3664936029911041; Validation acc = 84.24\n",
            "Epoch 5:\n",
            "Batch 0 : training loss = 0.21688640117645264; training acc = 91.5\n",
            "Batch 20 : training loss = 0.24151599407196045; training acc = 92.0\n",
            "Batch 40 : training loss = 0.2154141217470169; training acc = 92.0\n",
            "Batch 60 : training loss = 0.22941291332244873; training acc = 90.0\n",
            "Batch 80 : training loss = 0.230417862534523; training acc = 90.5\n",
            "Epoch 5 : Validation loss = 0.36900466307997704; Validation acc = 84.22\n",
            "Early stopping.\n",
            "Epoch 5 : Test loss = 0.41132731600105765; Test acc = 81.5\n",
            "########### PRETRAINING WITHOUT FINETUNING #############\n",
            "Beginning training...\n",
            "Epoch 1:\n",
            "Batch 0 : training loss = 0.69489586353302; training acc = 51.0\n",
            "Batch 20 : training loss = 0.6902654767036438; training acc = 52.0\n",
            "Batch 40 : training loss = 0.6859297156333923; training acc = 54.0\n",
            "Batch 60 : training loss = 0.6856784224510193; training acc = 58.0\n",
            "Batch 80 : training loss = 0.6781103610992432; training acc = 57.5\n",
            "Epoch 1 : Validation loss = 0.6824855753779411; Validation acc = 58.3\n",
            "Epoch 2:\n",
            "Batch 0 : training loss = 0.6856098771095276; training acc = 58.5\n",
            "Batch 20 : training loss = 0.6809032559394836; training acc = 61.5\n",
            "Batch 40 : training loss = 0.670682966709137; training acc = 63.0\n",
            "Batch 60 : training loss = 0.6755675673484802; training acc = 60.0\n",
            "Batch 80 : training loss = 0.662899911403656; training acc = 65.5\n",
            "Epoch 2 : Validation loss = 0.6758743634819985; Validation acc = 58.74\n",
            "Epoch 3:\n",
            "Batch 0 : training loss = 0.6656471490859985; training acc = 64.5\n",
            "Batch 20 : training loss = 0.6812618970870972; training acc = 59.5\n",
            "Batch 40 : training loss = 0.6708776354789734; training acc = 62.0\n",
            "Batch 60 : training loss = 0.6673833727836609; training acc = 63.5\n",
            "Batch 80 : training loss = 0.6617031097412109; training acc = 61.5\n",
            "Epoch 3 : Validation loss = 0.6707525652647018; Validation acc = 59.56\n",
            "Epoch 4:\n",
            "Batch 0 : training loss = 0.6693611741065979; training acc = 63.0\n",
            "Batch 20 : training loss = 0.6678562164306641; training acc = 62.0\n",
            "Batch 40 : training loss = 0.6920820474624634; training acc = 50.5\n",
            "Batch 60 : training loss = 0.667998194694519; training acc = 62.0\n",
            "Batch 80 : training loss = 0.6419622898101807; training acc = 70.0\n",
            "Epoch 4 : Validation loss = 0.6672817432880401; Validation acc = 59.96\n",
            "Epoch 5:\n",
            "Batch 0 : training loss = 0.6503448486328125; training acc = 66.5\n",
            "Batch 20 : training loss = 0.6780231595039368; training acc = 59.5\n",
            "Batch 40 : training loss = 0.649290144443512; training acc = 64.0\n",
            "Batch 60 : training loss = 0.6595394611358643; training acc = 59.5\n",
            "Batch 80 : training loss = 0.6539545655250549; training acc = 63.5\n",
            "Epoch 5 : Validation loss = 0.6649036979675294; Validation acc = 60.04\n",
            "Epoch 5 : Test loss = 0.6595186561644077; Test acc = 61.36\n",
            "########### PRETRAINING WITH FINETUNING ##############\n",
            "Beginning training...\n",
            "Epoch 1:\n",
            "Batch 0 : training loss = 0.6952177286148071; training acc = 46.0\n",
            "Batch 20 : training loss = 0.6787463426589966; training acc = 55.5\n",
            "Batch 40 : training loss = 0.6556363105773926; training acc = 66.0\n",
            "Batch 60 : training loss = 0.6135583519935608; training acc = 75.5\n",
            "Batch 80 : training loss = 0.5427136421203613; training acc = 77.0\n",
            "Epoch 1 : Validation loss = 0.5219884118437768; Validation acc = 76.46\n",
            "Epoch 2:\n",
            "Batch 0 : training loss = 0.5063754916191101; training acc = 79.5\n",
            "Batch 20 : training loss = 0.4689827859401703; training acc = 79.5\n",
            "Batch 40 : training loss = 0.4051641821861267; training acc = 85.0\n",
            "Batch 60 : training loss = 0.4249139130115509; training acc = 82.0\n",
            "Batch 80 : training loss = 0.3544046878814697; training acc = 87.0\n",
            "Epoch 2 : Validation loss = 0.39608345113694665; Validation acc = 83.12\n",
            "Epoch 3:\n",
            "Batch 0 : training loss = 0.35074782371520996; training acc = 86.5\n",
            "Batch 20 : training loss = 0.28835803270339966; training acc = 93.0\n",
            "Batch 40 : training loss = 0.35578373074531555; training acc = 86.5\n",
            "Batch 60 : training loss = 0.3019048273563385; training acc = 87.0\n",
            "Batch 80 : training loss = 0.2846698462963104; training acc = 88.0\n",
            "Epoch 3 : Validation loss = 0.36582691960036756; Validation acc = 83.92\n",
            "Epoch 4:\n",
            "Batch 0 : training loss = 0.22683627903461456; training acc = 93.0\n",
            "Batch 20 : training loss = 0.23965735733509064; training acc = 92.0\n",
            "Batch 40 : training loss = 0.24058464169502258; training acc = 90.0\n",
            "Batch 60 : training loss = 0.26320528984069824; training acc = 90.0\n",
            "Batch 80 : training loss = 0.2207087278366089; training acc = 93.0\n",
            "Epoch 4 : Validation loss = 0.3581009109318256; Validation acc = 84.58\n",
            "Epoch 5:\n",
            "Batch 0 : training loss = 0.18086378276348114; training acc = 94.5\n",
            "Batch 20 : training loss = 0.17430727183818817; training acc = 95.0\n",
            "Batch 40 : training loss = 0.21520061790943146; training acc = 93.0\n",
            "Batch 60 : training loss = 0.1597471833229065; training acc = 94.0\n",
            "Batch 80 : training loss = 0.17978908121585846; training acc = 93.5\n",
            "Epoch 5 : Validation loss = 0.363923938088119; Validation acc = 84.44\n",
            "Early stopping.\n",
            "Epoch 5 : Test loss = 0.41570294021442533; Test acc = 81.496\n",
            "--------MINFREQ = 10 ----------\n",
            "Beginning training...\n",
            "Epoch 1:\n",
            "Batch 0 : training loss = 0.6939796209335327; training acc = 51.5\n",
            "Batch 20 : training loss = 0.672537624835968; training acc = 64.0\n",
            "Batch 40 : training loss = 0.6441735029220581; training acc = 69.5\n",
            "Batch 60 : training loss = 0.6042243242263794; training acc = 73.0\n",
            "Batch 80 : training loss = 0.6020099520683289; training acc = 66.5\n",
            "Epoch 1 : Validation loss = 0.5457788634300232; Validation acc = 74.16\n",
            "Epoch 2:\n",
            "Batch 0 : training loss = 0.5085630416870117; training acc = 81.0\n",
            "Batch 20 : training loss = 0.4470860958099365; training acc = 84.5\n",
            "Batch 40 : training loss = 0.4556027352809906; training acc = 80.5\n",
            "Batch 60 : training loss = 0.43254271149635315; training acc = 79.5\n",
            "Batch 80 : training loss = 0.43234971165657043; training acc = 82.0\n",
            "Epoch 2 : Validation loss = 0.4229343744367361; Validation acc = 80.74\n",
            "Epoch 3:\n",
            "Batch 0 : training loss = 0.41238296031951904; training acc = 83.0\n",
            "Batch 20 : training loss = 0.2938029170036316; training acc = 91.0\n",
            "Batch 40 : training loss = 0.3096604645252228; training acc = 88.5\n",
            "Batch 60 : training loss = 0.3138783574104309; training acc = 87.0\n",
            "Batch 80 : training loss = 0.43721550703048706; training acc = 79.0\n",
            "Epoch 3 : Validation loss = 0.382284312620759; Validation acc = 82.94\n",
            "Epoch 4:\n",
            "Batch 0 : training loss = 0.2851971387863159; training acc = 91.5\n",
            "Batch 20 : training loss = 0.30670639872550964; training acc = 87.0\n",
            "Batch 40 : training loss = 0.24138034880161285; training acc = 92.0\n",
            "Batch 60 : training loss = 0.21979229152202606; training acc = 91.5\n",
            "Batch 80 : training loss = 0.22907932102680206; training acc = 91.5\n",
            "Epoch 4 : Validation loss = 0.3673809237033129; Validation acc = 83.9\n",
            "Epoch 5:\n",
            "Batch 0 : training loss = 0.24402275681495667; training acc = 92.5\n",
            "Batch 20 : training loss = 0.20950503647327423; training acc = 93.5\n",
            "Batch 40 : training loss = 0.24657118320465088; training acc = 90.0\n",
            "Batch 60 : training loss = 0.28465554118156433; training acc = 89.0\n",
            "Batch 80 : training loss = 0.21468116343021393; training acc = 93.0\n",
            "Epoch 5 : Validation loss = 0.36697448618710043; Validation acc = 83.94\n",
            "Epoch 5 : Test loss = 0.4045734513103962; Test acc = 81.812\n",
            "########### PRETRAINING WITHOUT FINETUNING #############\n",
            "Beginning training...\n",
            "Epoch 1:\n",
            "Batch 0 : training loss = 0.6940923929214478; training acc = 48.5\n",
            "Batch 20 : training loss = 0.6859143972396851; training acc = 53.5\n",
            "Batch 40 : training loss = 0.6939247846603394; training acc = 50.5\n",
            "Batch 60 : training loss = 0.6790465712547302; training acc = 60.5\n",
            "Batch 80 : training loss = 0.6836303472518921; training acc = 52.0\n",
            "Epoch 1 : Validation loss = 0.6826348426938057; Validation acc = 58.04\n",
            "Epoch 2:\n",
            "Batch 0 : training loss = 0.6783586144447327; training acc = 58.5\n",
            "Batch 20 : training loss = 0.6812496781349182; training acc = 55.5\n",
            "Batch 40 : training loss = 0.6818623542785645; training acc = 61.0\n",
            "Batch 60 : training loss = 0.6736857891082764; training acc = 63.0\n",
            "Batch 80 : training loss = 0.6705521941184998; training acc = 65.5\n",
            "Epoch 2 : Validation loss = 0.6763653072714806; Validation acc = 58.98\n",
            "Epoch 3:\n",
            "Batch 0 : training loss = 0.6678773760795593; training acc = 59.5\n",
            "Batch 20 : training loss = 0.6858790516853333; training acc = 57.0\n",
            "Batch 40 : training loss = 0.6680727601051331; training acc = 62.5\n",
            "Batch 60 : training loss = 0.6688815951347351; training acc = 59.5\n",
            "Batch 80 : training loss = 0.6832323670387268; training acc = 58.5\n",
            "Epoch 3 : Validation loss = 0.6714285641908646; Validation acc = 59.82\n",
            "Epoch 4:\n",
            "Batch 0 : training loss = 0.6687216758728027; training acc = 58.5\n",
            "Batch 20 : training loss = 0.6692153215408325; training acc = 55.5\n",
            "Batch 40 : training loss = 0.6715742349624634; training acc = 60.0\n",
            "Batch 60 : training loss = 0.6583824157714844; training acc = 63.5\n",
            "Batch 80 : training loss = 0.6440083384513855; training acc = 70.5\n",
            "Epoch 4 : Validation loss = 0.6687766999006272; Validation acc = 59.44\n",
            "Epoch 5:\n",
            "Batch 0 : training loss = 0.6553634405136108; training acc = 62.5\n",
            "Batch 20 : training loss = 0.6622869968414307; training acc = 63.0\n",
            "Batch 40 : training loss = 0.6689755916595459; training acc = 66.0\n",
            "Batch 60 : training loss = 0.6499279141426086; training acc = 63.0\n",
            "Batch 80 : training loss = 0.6766205430030823; training acc = 58.0\n",
            "Epoch 5 : Validation loss = 0.6638526558876038; Validation acc = 60.5\n",
            "Epoch 5 : Test loss = 0.6600022146701813; Test acc = 61.82\n",
            "########### PRETRAINING WITH FINETUNING ##############\n",
            "Beginning training...\n",
            "Epoch 1:\n",
            "Batch 0 : training loss = 0.6953800320625305; training acc = 47.0\n",
            "Batch 20 : training loss = 0.6701220870018005; training acc = 64.5\n",
            "Batch 40 : training loss = 0.6630291938781738; training acc = 61.5\n",
            "Batch 60 : training loss = 0.6299960613250732; training acc = 69.0\n",
            "Batch 80 : training loss = 0.55049729347229; training acc = 77.0\n",
            "Epoch 1 : Validation loss = 0.5280536273121834; Validation acc = 76.68\n",
            "Epoch 2:\n",
            "Batch 0 : training loss = 0.5021815896034241; training acc = 80.0\n",
            "Batch 20 : training loss = 0.43422916531562805; training acc = 84.5\n",
            "Batch 40 : training loss = 0.3825817406177521; training acc = 85.5\n",
            "Batch 60 : training loss = 0.37446263432502747; training acc = 85.5\n",
            "Batch 80 : training loss = 0.37459874153137207; training acc = 84.5\n",
            "Epoch 2 : Validation loss = 0.40093827322125436; Validation acc = 83.0\n",
            "Epoch 3:\n",
            "Batch 0 : training loss = 0.37554654479026794; training acc = 84.5\n",
            "Batch 20 : training loss = 0.28879544138908386; training acc = 93.0\n",
            "Batch 40 : training loss = 0.30866366624832153; training acc = 86.0\n",
            "Batch 60 : training loss = 0.2766859531402588; training acc = 88.0\n",
            "Batch 80 : training loss = 0.3058931231498718; training acc = 86.5\n",
            "Epoch 3 : Validation loss = 0.3679989057034254; Validation acc = 84.16\n",
            "Epoch 4:\n",
            "Batch 0 : training loss = 0.2536669373512268; training acc = 90.0\n",
            "Batch 20 : training loss = 0.22114601731300354; training acc = 93.5\n",
            "Batch 40 : training loss = 0.25395798683166504; training acc = 89.5\n",
            "Batch 60 : training loss = 0.2257772833108902; training acc = 91.5\n",
            "Batch 80 : training loss = 0.27593758702278137; training acc = 88.0\n",
            "Epoch 4 : Validation loss = 0.3627142331749201; Validation acc = 84.04\n",
            "Epoch 5:\n",
            "Batch 0 : training loss = 0.22382697463035583; training acc = 92.5\n",
            "Batch 20 : training loss = 0.21042421460151672; training acc = 91.5\n",
            "Batch 40 : training loss = 0.198624387383461; training acc = 93.5\n",
            "Batch 60 : training loss = 0.22121918201446533; training acc = 91.5\n",
            "Batch 80 : training loss = 0.16322088241577148; training acc = 95.0\n",
            "Epoch 5 : Validation loss = 0.36638179685920474; Validation acc = 83.94\n",
            "Early stopping.\n",
            "Epoch 5 : Test loss = 0.4104680735580623; Test acc = 81.78\n",
            "--------MINFREQ = 15 ----------\n",
            "Beginning training...\n",
            "Epoch 1:\n",
            "Batch 0 : training loss = 0.6932048797607422; training acc = 47.0\n",
            "Batch 20 : training loss = 0.6693757772445679; training acc = 63.0\n",
            "Batch 40 : training loss = 0.6578832268714905; training acc = 59.5\n",
            "Batch 60 : training loss = 0.6268488764762878; training acc = 68.5\n",
            "Batch 80 : training loss = 0.5617842078208923; training acc = 76.5\n",
            "Epoch 1 : Validation loss = 0.5484554770588875; Validation acc = 74.7\n",
            "Epoch 2:\n",
            "Batch 0 : training loss = 0.5135985016822815; training acc = 82.0\n",
            "Batch 20 : training loss = 0.48233768343925476; training acc = 79.5\n",
            "Batch 40 : training loss = 0.43553411960601807; training acc = 83.0\n",
            "Batch 60 : training loss = 0.3734426498413086; training acc = 89.0\n",
            "Batch 80 : training loss = 0.40514323115348816; training acc = 85.0\n",
            "Epoch 2 : Validation loss = 0.4270461876690388; Validation acc = 80.88\n",
            "Epoch 3:\n",
            "Batch 0 : training loss = 0.3521419167518616; training acc = 85.5\n",
            "Batch 20 : training loss = 0.39762741327285767; training acc = 82.0\n",
            "Batch 40 : training loss = 0.3481465280056; training acc = 88.0\n",
            "Batch 60 : training loss = 0.31352901458740234; training acc = 87.5\n",
            "Batch 80 : training loss = 0.29718807339668274; training acc = 90.5\n",
            "Epoch 3 : Validation loss = 0.3848409152776003; Validation acc = 83.44\n",
            "Epoch 4:\n",
            "Batch 0 : training loss = 0.2981679439544678; training acc = 86.0\n",
            "Batch 20 : training loss = 0.2786276042461395; training acc = 90.0\n",
            "Batch 40 : training loss = 0.34895315766334534; training acc = 82.5\n",
            "Batch 60 : training loss = 0.2437238246202469; training acc = 92.0\n",
            "Batch 80 : training loss = 0.31378787755966187; training acc = 86.5\n",
            "Epoch 4 : Validation loss = 0.3702251087129116; Validation acc = 83.94\n",
            "Epoch 5:\n",
            "Batch 0 : training loss = 0.24969325959682465; training acc = 92.5\n",
            "Batch 20 : training loss = 0.2729453146457672; training acc = 88.5\n",
            "Batch 40 : training loss = 0.22628918290138245; training acc = 90.0\n",
            "Batch 60 : training loss = 0.2267676591873169; training acc = 90.5\n",
            "Batch 80 : training loss = 0.2483629435300827; training acc = 90.5\n",
            "Epoch 5 : Validation loss = 0.3694240206480026; Validation acc = 83.92\n",
            "Epoch 5 : Test loss = 0.4061523680239916; Test acc = 81.62\n",
            "########### PRETRAINING WITHOUT FINETUNING #############\n",
            "Beginning training...\n",
            "Epoch 1:\n",
            "Batch 0 : training loss = 0.6879006028175354; training acc = 55.0\n",
            "Batch 20 : training loss = 0.6860896348953247; training acc = 54.5\n",
            "Batch 40 : training loss = 0.6836495995521545; training acc = 58.5\n",
            "Batch 60 : training loss = 0.6847752928733826; training acc = 54.0\n",
            "Batch 80 : training loss = 0.6827687621116638; training acc = 58.0\n",
            "Epoch 1 : Validation loss = 0.6824083203077316; Validation acc = 57.68\n",
            "Epoch 2:\n",
            "Batch 0 : training loss = 0.673129677772522; training acc = 60.5\n",
            "Batch 20 : training loss = 0.6775877475738525; training acc = 62.0\n",
            "Batch 40 : training loss = 0.6767851114273071; training acc = 57.0\n",
            "Batch 60 : training loss = 0.6767944097518921; training acc = 61.0\n",
            "Batch 80 : training loss = 0.675536572933197; training acc = 61.0\n",
            "Epoch 2 : Validation loss = 0.6757743567228317; Validation acc = 58.98\n",
            "Epoch 3:\n",
            "Batch 0 : training loss = 0.6703827381134033; training acc = 58.5\n",
            "Batch 20 : training loss = 0.6738712191581726; training acc = 59.5\n",
            "Batch 40 : training loss = 0.6699855923652649; training acc = 61.0\n",
            "Batch 60 : training loss = 0.6708301305770874; training acc = 55.5\n",
            "Batch 80 : training loss = 0.6685478091239929; training acc = 58.5\n",
            "Epoch 3 : Validation loss = 0.6707030987739563; Validation acc = 59.6\n",
            "Epoch 4:\n",
            "Batch 0 : training loss = 0.6616988182067871; training acc = 67.0\n",
            "Batch 20 : training loss = 0.670332670211792; training acc = 60.0\n",
            "Batch 40 : training loss = 0.6803408265113831; training acc = 58.0\n",
            "Batch 60 : training loss = 0.6648319363594055; training acc = 63.5\n",
            "Batch 80 : training loss = 0.6818652153015137; training acc = 55.0\n",
            "Epoch 4 : Validation loss = 0.6665994247794151; Validation acc = 60.28\n",
            "Epoch 5:\n",
            "Batch 0 : training loss = 0.6603467464447021; training acc = 64.5\n",
            "Batch 20 : training loss = 0.6683505773544312; training acc = 61.0\n",
            "Batch 40 : training loss = 0.6563284397125244; training acc = 65.5\n",
            "Batch 60 : training loss = 0.6639390587806702; training acc = 61.5\n",
            "Batch 80 : training loss = 0.6683822870254517; training acc = 63.5\n",
            "Epoch 5 : Validation loss = 0.6625648194551468; Validation acc = 60.66\n",
            "Epoch 5 : Test loss = 0.6582249174714089; Test acc = 62.208\n",
            "########### PRETRAINING WITH FINETUNING ##############\n",
            "Beginning training...\n",
            "Epoch 1:\n",
            "Batch 0 : training loss = 0.6923912167549133; training acc = 54.0\n",
            "Batch 20 : training loss = 0.6703218817710876; training acc = 57.5\n",
            "Batch 40 : training loss = 0.6530961394309998; training acc = 66.5\n",
            "Batch 60 : training loss = 0.6252362132072449; training acc = 68.0\n",
            "Batch 80 : training loss = 0.5589541792869568; training acc = 74.5\n",
            "Epoch 1 : Validation loss = 0.5269511707127095; Validation acc = 76.72\n",
            "Epoch 2:\n",
            "Batch 0 : training loss = 0.5134279131889343; training acc = 78.0\n",
            "Batch 20 : training loss = 0.41518497467041016; training acc = 85.0\n",
            "Batch 40 : training loss = 0.4654501676559448; training acc = 78.5\n",
            "Batch 60 : training loss = 0.377493292093277; training acc = 88.0\n",
            "Batch 80 : training loss = 0.3331882953643799; training acc = 89.0\n",
            "Epoch 2 : Validation loss = 0.4037495682388544; Validation acc = 82.56\n",
            "Epoch 3:\n",
            "Batch 0 : training loss = 0.33329346776008606; training acc = 86.0\n",
            "Batch 20 : training loss = 0.35409337282180786; training acc = 83.5\n",
            "Batch 40 : training loss = 0.28528785705566406; training acc = 91.0\n",
            "Batch 60 : training loss = 0.31759923696517944; training acc = 88.0\n",
            "Batch 80 : training loss = 0.33055633306503296; training acc = 85.5\n",
            "Epoch 3 : Validation loss = 0.37088600888848305; Validation acc = 83.84\n",
            "Epoch 4:\n",
            "Batch 0 : training loss = 0.2814732789993286; training acc = 89.0\n",
            "Batch 20 : training loss = 0.2331911325454712; training acc = 91.5\n",
            "Batch 40 : training loss = 0.2659620940685272; training acc = 91.5\n",
            "Batch 60 : training loss = 0.285164475440979; training acc = 89.5\n",
            "Batch 80 : training loss = 0.25225022435188293; training acc = 87.5\n",
            "Epoch 4 : Validation loss = 0.36495337173342707; Validation acc = 84.1\n",
            "Epoch 5:\n",
            "Batch 0 : training loss = 0.23532871901988983; training acc = 91.0\n",
            "Batch 20 : training loss = 0.22768297791481018; training acc = 89.5\n",
            "Batch 40 : training loss = 0.24763961136341095; training acc = 92.5\n",
            "Batch 60 : training loss = 0.17663170397281647; training acc = 93.5\n",
            "Batch 80 : training loss = 0.3067198693752289; training acc = 85.5\n",
            "Epoch 5 : Validation loss = 0.3684135790169239; Validation acc = 84.06\n",
            "Early stopping.\n",
            "Epoch 5 : Test loss = 0.4095529368445277; Test acc = 81.84\n"
          ]
        }
      ],
      "source": [
        "print(\"########### NO PRETRAINING ##############\")\n",
        "for freq in [5, 10, 15]:\n",
        "  print(f\"--------MINFREQ = {freq} ----------\")\n",
        "\n",
        "  training_dataset = TextClassificationDataset(train_texts_splt, train_labels_splt, min_freq = freq)\n",
        "  training_word2idx, training_idx2word = training_dataset.get_vocab()\n",
        "  valid_dataset = TextClassificationDataset(val_texts, val_labels, (training_word2idx, training_idx2word), min_freq = freq)\n",
        "  test_dataset = TextClassificationDataset(test_texts, test_labels, (training_word2idx, training_idx2word), min_freq = freq)\n",
        "  training_dataloader = DataLoader(training_dataset, batch_size = 200, shuffle=True)\n",
        "  valid_dataloader = DataLoader(valid_dataset, batch_size = 25)\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size = 25)\n",
        "  \n",
        "  model = AveragingModel(300, len(training_word2idx))\n",
        "  opt = optim.Adam(model.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  train_losses = experiment(model, opt, criterion)\n",
        "\n",
        "  print(\"########### PRETRAINING WITHOUT FINETUNING #############\")\n",
        "\n",
        "  model = PretrainedAveragingModel(torch.FloatTensor(GloveEmbeddings))\n",
        "  opt = optim.Adam(model.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  train_losses = experiment(model, opt, criterion)\n",
        "\n",
        "  print(\"########### PRETRAINING WITH FINETUNING ##############\")\n",
        "\n",
        "  model = PretrainedAveragingModel(torch.FloatTensor(GloveEmbeddings), fine_tune = True)\n",
        "  opt = optim.Adam(model.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  train_losses = experiment(model, opt, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTl3gbSUMBLw"
      },
      "source": [
        "## 5 - Creating a LSTM model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HuLBF1IWA_Vh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "8yaj6nLJMDR4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1d14ec-03b9-4cc9-9fe2-96e55910508d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 1, 3])\n",
            "--------------------------------------------------------\n",
            "(tensor([[[0.0018, 0.0540, 0.0370]]], grad_fn=<StackBackward0>), tensor([[[0.0032, 0.1141, 0.0826]]], grad_fn=<StackBackward0>))\n"
          ]
        }
      ],
      "source": [
        "# Create a toy example of LSTM: \n",
        "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
        "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
        "# LSTMs expect inputs having 3 dimensions:\n",
        "# - The first dimension is the temporal dimension, along which we (in our case) have the different words\n",
        "# - The second dimension is the batch dimension, along which we stack the independant batches\n",
        "# - The third dimension is the feature dimension, along which are the features of the vector representing the words\n",
        "\n",
        "# In our toy case, we have inputs and outputs containing 3 features (third dimension !)\n",
        "# We created a sequence of 5 different inputs (first dimension !)\n",
        "# We don't use batch (the second dimension will have one lement)\n",
        "\n",
        "# We need an initial hidden state, of the right sizes for dimension 2/3, but with only one temporal element:\n",
        "# Here, it is:\n",
        "hidden = (torch.randn(1, 1, 3),\n",
        "          torch.randn(1, 1, 3))\n",
        "# Why do we create a tuple of two tensors ? Because we use LSTMs: remember that they use two sets of weights,\n",
        "# and two hidden states (Hidden state, and Cell state).\n",
        "# If you don't remember, read: https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "# If we used a classic RNN, we would simply have:\n",
        "# hidden = torch.randn(1, 1, 3)\n",
        "\n",
        "# The naive way of applying a lstm to inputs is to apply it one step at a time, and loop through the sequence\n",
        "for i in inputs:\n",
        "    # After each step, hidden contains the hidden states (remember, it's a tuple of two states).\n",
        "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
        "    \n",
        "# Alternatively, we can do the entire sequence all at once.\n",
        "# The first value returned by LSTM is all of the Hidden states throughout the sequence.\n",
        "# The second is just the most recent Hidden state and Cell state (you can compare the values)\n",
        "# The reason for this is that:\n",
        "# \"out\" will give you access to all hidden states in the sequence, for each temporal step\n",
        "# \"hidden\" will allow you to continue the sequence and backpropagate later, with another sequence\n",
        "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
        "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # Re-initialize\n",
        "out, hidden = lstm(inputs, hidden)\n",
        "print(out.shape)\n",
        "print('--------------------------------------------------------')\n",
        "print(hidden)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxCCoIVwMEoX"
      },
      "source": [
        "We'll implement now a LSTM model, taking the same inputs and also outputing a score for the sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P31Gh62obzPw"
      },
      "source": [
        "<div class='alert alert-block alert-info'>\n",
        "            Code:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "7obmINvlMGCB"
      },
      "outputs": [],
      "source": [
        "# Models are usually implemented as custom nn.Module subclass\n",
        "# We need to redefine the __init__ method, which creates the object\n",
        "# We also need to redefine the forward method, which transform the input into outputs\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, vocabulary_size, hidden_dim, embeddings=None, fine_tuning=False):\n",
        "      # To complete     \n",
        "      super().__init__()\n",
        "      self.hidden_dim = hidden_dim\n",
        "      if embeddings is None:\n",
        "        self.embedding = nn.Embedding(vocabulary_size+1, embedding_dim)\n",
        "      else :\n",
        "        self.embedding = nn.Embedding.from_pretrained(embeddings.requires_grad_(fine_tuning))\n",
        "\n",
        "      # Create a linear layer that will transform the mean of the embeddings into a classification score\n",
        "      self.lstm = nn.LSTM(embedding_dim, hidden_dim, 1, batch_first=True)\n",
        "      # No need for sigmoid, it will be into the criterion ! \n",
        "      self.linear = nn.Linear(hidden_dim, 1)\n",
        "      \n",
        "    def forward(self, inputs):\n",
        "      # Remember: the inputs are written as Batch_size * seq_length * embedding_dim\n",
        "      inputs = self.embedding(inputs)\n",
        "      hidden = (torch.randn(1, np.shape(inputs)[0], self.hidden_dim), \n",
        "                torch.randn(1, np.shape(inputs)[0], self.hidden_dim))\n",
        "      output, (hidden, cell) = self.lstm(inputs, hidden)\n",
        "      o = self.linear(cell).squeeze()\n",
        "      return o\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(100, len(training_word2idx), 10)\n",
        "# Create an optimizer\n",
        "opt = optim.Adam(model.parameters(), lr=0.005, betas=(0.9, 0.999))\n",
        "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "train_losses = experiment(model, opt, criterion)\n",
        "\n",
        "plt.plot(train_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        },
        "id": "seflbGrn8Hx8",
        "outputId": "e7156111-af8a-4ec4-b192-3305b2fefc32"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning training...\n",
            "Epoch 1:\n",
            "Batch 0 : training loss = 0.6978667974472046; training acc = 55.0\n",
            "Batch 20 : training loss = 0.7099014520645142; training acc = 53.0\n",
            "Batch 40 : training loss = 0.6756012439727783; training acc = 60.5\n",
            "Batch 60 : training loss = 0.6949223875999451; training acc = 50.0\n",
            "Batch 80 : training loss = 0.6911258101463318; training acc = 51.0\n",
            "Epoch 1 : Validation loss = 0.690545780658722; Validation acc = 52.88\n",
            "Epoch 2:\n",
            "Batch 0 : training loss = 0.6601669192314148; training acc = 63.5\n",
            "Batch 20 : training loss = 0.655239999294281; training acc = 61.5\n",
            "Batch 40 : training loss = 0.6408723592758179; training acc = 60.0\n",
            "Batch 60 : training loss = 0.593522310256958; training acc = 70.5\n",
            "Batch 80 : training loss = 0.5957775712013245; training acc = 71.0\n",
            "Epoch 2 : Validation loss = 0.5638968421518803; Validation acc = 71.22\n",
            "Epoch 3:\n",
            "Batch 0 : training loss = 0.4395224452018738; training acc = 80.0\n",
            "Batch 20 : training loss = 0.4541233777999878; training acc = 77.5\n",
            "Batch 40 : training loss = 0.41388139128685; training acc = 82.5\n",
            "Batch 60 : training loss = 0.44247162342071533; training acc = 81.5\n",
            "Batch 80 : training loss = 0.38018798828125; training acc = 84.0\n",
            "Epoch 3 : Validation loss = 0.49394853472709654; Validation acc = 76.02\n",
            "Epoch 4:\n",
            "Batch 0 : training loss = 0.24831940233707428; training acc = 94.0\n",
            "Batch 20 : training loss = 0.2254467010498047; training acc = 93.0\n",
            "Batch 40 : training loss = 0.2516593337059021; training acc = 91.0\n",
            "Batch 60 : training loss = 0.2520695924758911; training acc = 89.0\n",
            "Batch 80 : training loss = 0.286530464887619; training acc = 88.5\n",
            "Epoch 4 : Validation loss = 0.5401514454185963; Validation acc = 77.76\n",
            "Early stopping.\n",
            "Epoch 4 : Test loss = 0.5946551614627242; Test acc = 75.96\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f20a0bc8e50>]"
            ]
          },
          "metadata": {},
          "execution_count": 131
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29eZgb1ZX+/x7tUu+r2+52493GxjZgY2P2LWAggxMCCUsWIAwJCQnZJoEhkx9xQkjIQsIEfgwQtiEZIEASFgPB7NixsY03vLf3vbvt3qXWer9/VN3SVanUCy2pJfl8nsePpapS1ely+62j9557LgkhwDAMw+Q/tuEOgGEYhkkPLOgMwzAFAgs6wzBMgcCCzjAMUyCwoDMMwxQIjuG6cHV1tRgzZsxwXZ5hGCYvWbVqVasQosZq37AJ+pgxY7By5crhujzDMExeQkS7U+1jy4VhGKZAYEFnGIYpEFjQGYZhCgQWdIZhmAKBBZ1hGKZAYEFnGIYpEFjQGYZhCoSCEXR/KILnV+0DtwNmGOZYZdgmFqWbXyzahKeW7cGoci/mja8a7nAYhmGyTsFk6M2dQQBAmz80zJEwDMMMDwUj6C6H9qMEI9FhjoRhGGZ4KBxBt2s/ytGecL/HNjV3Y/WetkyHxDAMk1XyVtAXvrQRb20+HN9A2l9HuoP9fvaC372Lzz6wNEORMQzDDA95Kej72wN4dMlOPLNir7GtuzcCAGjtQ9D9oQh+8o+P+zy3ECKjlTJLm1px5j1vwR+KZOwaKtc8vAzPrtzb/4EMw+Q9AxJ0IppPRFuIqImIbrPYfy8RrdH/bCWi9vSHGue9rS0AgA0HOo1tHQHNamntTj0o+vyqfXjyX/HOk9FYsnB/9YmVuOPvfYv+UFj48kbsPRrAtsPdGbuGJByNYen2I/jhc+syfi2GYYaffgWdiOwA7gdwMYCpAK4moqnqMUKI7wohThRCnAjgvwG8kIlgJe9u0QR9X1vAEPJOPUNXLZdYTOD2F9Zj1W7NLzf76/Kza/e2Y+9RPwBgzd52LG1qTTguFImlLfaYnv139vbv9fdHW08Iv1+8FZGodXx9fVthGKbwGEiGPgdAkxBihxAiBOBpAAv6OP5qAP+XjuCsCEdjWNLUitGVXgDARj1L79TFeX97AKv3tOHGJ1biR8+vw/99uAc/+OtaAMDuIz0J5zrao2XzC+5fgjPveRv+UARHe0LYfdSPnqD2gFi1uw2TfvwqVu46CkDL6ve3B1LGF40JfOXRD7F0eys+2tNmPEwk8kuBLLMcCt99dg1+v3hbwjWEEPjq4ytw3m/fwYpd2nY5YMwwTGEzkIlF9QBUE3YfgLlWBxLRcQDGAnhr6KFZs3pPO7qCEdx87njc89oWHO7sBaBlvA0VXuxrCyQNeNaWuAEAW5u7ErZ/sK0FGw50GO8PtGvnEgLYcrgLJzdW4OV1BwAA72xpwewxlbj3ja3449tNWP6f58NGhOpiFx54ZzsaKrxYcGI9drR0492tLdh4sBMtXZpo77z7EhBpo7YxXdGbu4Ym6EIIvKN/U3lp3QE47DbMOq4C+9sDeHNzMwDg9Y8PAQBKPAUzf4xhmD5I9//0qwA8J4SwLAYnopsA3AQAjY2Nn+gCHzS1wm4jfOr4EbjntS3wh6L48d/Xo6s3gutPGwOH3YaDHb24es5oXPbHJQAAr8uOvUf92Hoo0be+86WNCe93tcYz+M0HNUFvatY+c0h/cPxzoyaSX/rTcmw93I37rj4Jv359CwDgspmjsOmQ9tBoUQR7Z2sPyrxOhKIxw2pp7uo19v/0pQ2wESEYieL2i49Hkbv/f5afv7LJeP3Usj14atke7PrlpcY3FkCzjwCg1Ovs93wMw+Q/AxH0/QBGK+8b9G1WXAXgm6lOJIR4CMBDADB79uxPVEpy6/kTcen0kagt9QAAeoIRPLVsj7aTCN8+f6Jx7HcvmIR7F2/Fke4QfvXaZjjthIoiNw6nsDuWbNe8cxsBmw52IhoTWKnbFpsOakLpdtgBAFv1Qc0nl+4yPr/pYFeCoEre3dqC3/5zK7qD8coWmaEf7uzFY0vi53hp7UFcOasBP/70VPNpDMLRGJ5athuXzhiJV9YdjJ+zsxcbDnSCCHDYyLCGvE57ynMxDFM4DETQVwCYSERjoQn5VQCuMR9ERFMAVAD4V1ojNGG3ESbXlSCsDwTuULLqhgpvwrG3XjARe4768e7WZmxv6cZnTqrHredPxItrDuCuRZtg5t0tLbDbCDMayrD5UCcOtAcQCEdR5nViw4FOvLT2QELmDQArFf/6+sc/TKicaaz0oScYwdbDXQliDgCHOrQM/aW1BxK2dwTCeGzpLtxwxlg0NXejJxiBy2HD7xdvw+0XT8GY6iK0+UMIRmK4aFpdgqDP+cWbmFJXgrHVRXDZbdisf1vo5dmzDHNM0O9omRAiAuAWAK8D2ATgWSHEBiJaSESXKYdeBeBpkaV2h067DU47GZnzb66cic+d3JB0XHWJC63dIfhDUZwzqQYjSj3497PGWZ5zR2sPpo0qxQmjyrBiVxvOvOdtAMDCBdNQWeTCwpc3GtYLAJwxoRoAMLOhDC/dcgaO9oQSyiYbKryo1319lbHVRVi1uw1/WLwNy3YcwbiaIrz8rTOM/dGYwKMf7MSXH/0QN//5I3z1iZVYv78D1zyyHKf98i1c+aD2zDyxodz4zJS6EgDA5kOaVTSqPP5wC4RY0BnmWGBA5Q9CiEVCiElCiPFCiLv0bT8RQryoHHOnECKpRj2TeJ12Q9BPHVcJu42SjqkuchuvT9MFGABuOH0sHrj2ZOP99aePAQB8ed4YjKspSjjHvPFVuHrOaCM7/8Vnp2PJbedhTLVPu/b4KkxvKMPL3zoTv7lyJr6mPzDqy72oL/cmVcU8fv0puGjaCNy7eCsWb2rGiQ3lOKG+DI9ddwqunNWAi0+owyMf7Ez5c/tDUdgIRqUPADx906nG67Mm1SSUWgbCLOgMcyyQ1/VsPpcDwUgMTjthZJnX8pjKIhcAYFxNEYqVwcaf/NtUXDJ9pPH+2+dNxA/nT8ZlM0fhoml1mDqy1NhXU+zGmKq4yJ8+oQr15V5j27xxWrveyXUluGJWgzEIWe5zGpU3KsdVFeH3XzjJeD+joQwAcO6UWvz6ypn42tnj4XLYcN6UWqz68QX4j4smJ3y+yGXH6985C0SEa+Y26tdy4Xg95jMmVGPiiGIAwIITR8FvkaG/vbkZH+/vSNqeboKRaMo6eYZh0kte17P53NpgX3251zI7B2BUjFjZMQDw/M3zsPuIHxVFLnzjnAkAgFHlXiy69UyMue0VAAARYWx1XNAbK7XM/MKpddh2uBunjkvsvx7Us2OP046qIpeRLR9X5cPvPn8iAK3y5oLjR2DxpsOYVl+W8PkTR5djy8/mG6WO3zx3At7Z0mzUlc8eU4mJIzSL5a7PnICfLzgBAPDE9adg48FOVBa58KP5U3Dt3Ea8su4QQpEYojGBlq4gitx2BMJRXP/4CpR4HFh/50V93OGhM/nHr+HsSTV44oY5Gb0OwzD5LuguTdBlFm7FhVNH4OEvz8b5U2ot9886rhKzjqu03PeXG+fCpj8oxiiCLoW2scqHX10xI+lz0s+e2VAOdUDh1vMnYtZxFcb7331hJl5ccwCzGitgRl5D8tSNcxEIRfHLVzfjm+dOSDhOHlpb6jGqfzxOOybUlsDr0mrS/aEITr37TUweUYL5J9QBANyO7HxBe1dv1cAwTGbJb0F3auH3Jeg2G+FTU0d8ovOrnnuVfo3PnlTf7+cumT4Si793NibUFht17ABQ4UuMs9TjxBdPPW5Asbgddrgddvzyc8kPkL7wurR7tE2PY8vhLoyvLTKuD2iC63HY0NTSjd/9cytW3HEBdh7pwd8+2o/vfWqS8VAbLFa9chiGyRx5LehePUMv96UW9HRBRNj8s/lwDnAa/YRazcMep2T25b7sT/Dx6TXolyuzZ+Xg7lF9daevPPphwmfa/CH88Ll1WLW7Df82cxQm6984BktPljpKMgyjkeeDoppYVWRJKD1Oe0qvPhVqdmvO0LOBvEcqcmJVRyCcMGNV3S/tmG2mdgkqO1t78POXN6I3RRVNT5AFnWGySV4Luk03j7ORoQ8FWcVS0Yc1lCk8FoK+56gfdhtBCOD9ra1J+w939qJG738jy0LNhCIxnPubd/DIBztTVsvIHvUA18IzTDbIa8tFrh/al4eeCzx5wxx8uPMoyoahp4ovxbT/ySNKsPFgJ97SG3mpXP/4CmOgdYNFKwMgcTHurl7rTLxLydBbu4MYrVcHMQyTGfI6Q5flgdmyXD4p5T4XLpxWNyzX7k3Ry1364q+sP4g5YyoTvH5A6zgJaO2Dw9FYUsuDLqWfe6re7j0mQWcYJrMUhKDLag0mmXnjqnDdaWOw/D/Px8aF8ZpzOfEIAL5wymiMry1O+qzdRujqjeCrT6zEKXctNma8rth1FL9fvM04ztynxtjeqwp6CL9YtAmPL0k9A5ZhmKGR34KuD8a5uZtgSlwOG+68bBpGlHrgczmMdgETauICfumMkbjutDFJn710+ki47DZjyb93tjRjw4EOXPngv/Cy0hRMWi4bDnTgl69uNtZkVS2XNn8ID723I6llMcMw6SOvBf28KVp9ubnLIpOaP3/1VFw9ZzTOnlyDr509Dq9950x4nHacPqEa2+66GD+4cJJx7KhyL75+dryR2ZNLd+PS+z5IOqe0X659ZDkefHe7sRygarmog6JZ6t/GMMcceT0o+q3zJuDaUxtRXezu/2AGgDa79e7LtclJt198fMI+p92GW86biN5wDH98uwluhw23nj8R88ZX44WP9uGvq/ZZnrOrN4IPdx5Fu18T9raeEMq8zgTLRe0n09odMqpoGIZJH3mdodtsxGKeATxO7deiNxKFzUaYN74KJzaWWx5b4XOipSuIz/9PvA3+Xz7cg12tPejWe7kTJQ6cbjucuradYZhPTl5n6ExmkHX9dqWfzLRRZZbHjij14OMDiXXoD723A93BCAhAqccBfyiKI0qVy+q97agpcRsNxrLJ0x/uwTmTa1FX5sn6tRkm0+R1hs5khitnN+Ab54zHzeeMN7ZNSTH9v9TjxN6jgaTte4/60R2MoMjtgM/lSFj449evb8Gn7n0v/YH3Q7s/hNteWI8vP7o869dmmGzAGTqThNthxw/nT0nY5nHacf6UWkxvKMOIUg9uf2E9AKDEY/0rtOeoHzYilHudEMK6Dl0IkdRVMpMQtGuZ+9MzTKHAGTozYP503Sn4zgWTcOWseG/54hSCvr8tgJauICqKXPC57DiiZOiSYCSGFbuOQgiBUCSGpz/cg2Akis7eMG58YiX2HvWnNf6oXl3DKzgxhQpn6MygcSgdJ+0pMuxITKCpuRuT60rQGQgnLOYteWLpLtz96mY8+MWTsWp3Gx5+fye8LjuaO4NYvOkwGiq8uPOyaWmLOxLTJqJx1SRTqHCGzgwJObD5rfMmJO0LRWOo8LngczmMVZvUZpXr9KZeX3/qIzz8vjaDtKs3gu0tWu/2dM8viPFKeEyBwxk684n4ny/NQrnXiVPGVOKauY0o8zrxzXMnYMp/vZZwXGWRM6GF78iy+KLZwXCywjZ3BY1FQSIpFsh4e3MzXt9waNCLfUQ5NWcKHM7QmU/ERdPqMHdcFWw2MrpIepx2vPn9s/Hyt86AQ0/FpYcuGVEanzdwtCc+UPq1s8ahutiN5s5eI0NP1U/9vW0teP4j60lOfRGNsqAzhQ1n6ExaGa/3iGmo8GLXET8qfS5jGTwAKFEaqe1RBj0bKn2oLXFjb5sfbfqM01RNv4KRGMJRgWhMDGrBEc7QmUKHM3QmI8je5xVFLhQpGbpXaaSm1qY3VvpQW+pO6L9ulaF3+MPo1dsIyH74A+0Nw2ucMoUOCzqTERp1Qa80WS4uh/Wv3OgKL2pL3EY/GADoCSaWF3b4w5i58J94YfV+AEBvOIYXPtqHsbcvStmTXSXGGTpT4LCgMxlhrL5gRlVR3HLpaw5RfYUXI0rj0/FddluS5dJimpwUjETxjzUHAAB/Xran35gi7KEzBQ4LOpMRrprTiCdvmIOqYreRoROAy0+uTzjuxjPG4q9fnwe3w248BADtgaBaLh2BMHaZatl7wzFM1BfmeGPjoX5jUjP0SJRrGJnCY0CCTkTziWgLETUR0W0pjvk8EW0kog1E9Jf0hsnkG8VuB86aVAMAGFejCfV3L5iEcybXYvPP5hvHnVBfhlPGVAIAZh1XYWwfXelNyNA/e/8S3PjkyoRrBCNRY9Uqsz1jheqh9/Ci1UwB0m+VCxHZAdwP4FMA9gFYQUQvCiE2KsdMBHA7gNOFEG1EVJupgJn848yJNdh218Vw6jNM3YqPXq9MHmpUFpEu8TjRE+rC/y7bjbFVRZYzTXvDMWNg1B/WxF9m3upsVola5dITjAzLot0Mk0kGUrY4B0CTEGIHABDR0wAWAFDXEvt3APcLIdoAQAiRvJQ8c0zjVARWbcilzgYlIkyvL8PRnhCK3Q70BKP4r79/nPKcveEoevXJSYGQ9vcl972PzkAEy/7z/KTj1QzdH7IuiWSYfGYggl4PYK/yfh+AuaZjJgEAES0BYAdwpxDiNTBMP9SWJPYl//s3TwegtdhVVzyyIhiJZ+iBUAS94Si2Hu5Oebwq6N0DsGgYJt9I16CoA8BEAOcAuBrAw0SUtMQNEd1ERCuJaGVLS0uaLs3kM+aJQXYbwW4jFLvtCPUzcNkbjnvo/nAU/9pxxNh37xtb0daT2OExpgh6mAdFmQJkIIK+H8Bo5X2Dvk1lH4AXhRBhIcROAFuhCXwCQoiHhBCzhRCza2pqPmnMzDFAkbv/L4/BSMzoByMEsG5vfOWkP7y5Df/1j0S7RvXQwxEWdKbwGIjlsgLARCIaC03IrwJwjemYv0PLzB8jompoFsyOdAbKFBbP3zwPHmXWqJmqAawV2xuOojeiLj4dTNqvojb76i/7Z5h8pF9BF0JEiOgWAK9D88cfFUJsIKKFAFYKIV7U911IRBsBRAH8hxDiSOqzMsc6s46r7HN/fXn/a36qGToAtHSZV0VKtHMSLReeZMQUHgNqziWEWARgkWnbT5TXAsD39D8MM2Tqy+MljG6HzfDKVYLhqDEoCiTPJFVnpu496sf721qN9yG2XJgChLstMjlJTYk74bXVOqBalUsMpR4HOnsjSZaLmp+f85t3EqpceFCUKUR46j+Tk6jVL1VFLstjZB16hb4/2XKJY+60yB46U4iwoDM5T6oOjbIOvdynCbrfNJ2/r2ZgnKEzhQgLOpOznD6hCjYCHDbt1/TS6SNR4om7hLIOvcJnPYWfkFrRuWyRKURY0Jmc5X9vmIttd12CeeOrAADfPn8iLjh+hLE/EIoiFNEWorai7wydq1yYwoMHRZmcxab76LecOwHzT6jDpBElCTm3XNSiPFWG3oegs4fOFCKcoTM5j81GmDSiRHujiHRHQBN0NUMvGcAMUyDuoe9V1jVlmHyHBZ3JK2xK2i2Xq1Mz9DLltfTQrWrOw9EY3t3agjPveRuvrDuYqXAZJquwoDN5xczRWs+32hI3Nh/qAgD4XPGsPMF+IU24/+O5tUnnCUcFtuqfX7W7LYMRM0z2YEFn8oovzm3EP797Fq47fYyxze2wGasiqfYLQRNrue6oSigSg9OuZfBcwsgUCizoTF5BpPnpU0eWGts8TjtObtSWr1MbchERlja1Jp3D7bAhHI3Bqde3q5bM0qZW/G31vkyFzzAZhQWdyUumjooLutthw5fnHQcAmDM23vRLCIEl25N7xHlddoSjMaNZ1zMr9+KnL20AAFzzyHJ895lki4Zh8gEWdCYvqS3x4POzGwBoy9jNaCjHzrsvwdyxVcYxHYEw1u5tT/qsx2FHKBJLmFn62JJdGY+ZYTINCzqTt9xzxUw03XUxxtUUA9AsFnXt0qXbjyASE3jsulNw6YyRxnaP04ZwVCS1CujS69oZJl/hiUVMXuOwJ+YkcqAT0BpyuRw2zBtfhZgQRnmix6ktb2deKHp7S0/mA2aYDMIZOlNQOE0CX1/uhcdpTxB+lz4oas7QtzenXmCaYfIBFnSmoHDYE+f7y2XunEo7XqddE/SASdD3t2s91112/m/B5Cf8m8sUFGYx9jq192qG7rQTwpFkD32P3gbAxv8rmDyFf3WZgsLsqXtdeoZuT8zQQ9EY/KZFpPcc0QQ9wp0YmTyFBZ0pKJwmy8UrLRfVQzcslwhOqC/FNXMbAcQz9EhMQFsml2HyCxZ0pqAwD4q6dUF32JM99J5gFCNKPDhrYg0A4FBnr3GMeck6hskHWNCZgsIs6DJDd9jMVS4CgXAUXpcdRW570nkiLOhMHsKCzhQU5iqXuOVi8tAjWh26z2VP6NZYqi9xxw27mHyEBZ0pKJKqXFzSclEzdDLq0H0uB3yueIZeV+YBwAOjTH7Cgs4UFA7bwOrQgxGtDt3nsqNIydDry70A2HJh8hMWdKagsNusLZfEOnQbOgJhRGICE0cUw6d46NPrywAAkdjgLJeP9rThsDKoyjDDAQs6U1AQmTN0ObEovl2KPACcf/yIhAx9dKUPwOAtl8sfWIpP/e7dQcfLMOlkQIJORPOJaAsRNRHRbRb7ryOiFiJao/+5Mf2hMszgMQZFlSqXq+c24pQxFbh2biNKPU5D9IF4lcwnGRTt7I30fxDDZJB+uy0SkR3A/QA+BWAfgBVE9KIQYqPp0GeEELdkIEaG+cTEB0XjGXp9uRd//fppxnuZ1c86rsKwbLgOnclHBpKhzwHQJITYIYQIAXgawILMhsUwn5wvntpovJZVL+bBUjPL//N8/PnGuco6oyzoTP4xEEGvB7BXeb9P32bmc0S0joieI6LRaYmOYT4BP//MdJw/pRZAfDDU7K2bGVHq0drs6tbMYAdFGSYXSNeg6EsAxgghZgB4A8ATVgcR0U1EtJKIVra0tKTp0gyTTFi3TMwTjfpDHj+YssUY2zNMjjAQQd8PQM24G/RtBkKII0KIoP72EQCzrE4khHhICDFbCDG7pqbmk8TLMAMiog9qOgfZC9fI0AdhuUS5kReTIwzkt30FgIlENJaIXACuAvCiegARjVTeXgZgU/pCZJjBIwXZXJfeH0aGPogqFx5AZXKFfgVdCBEBcAuA16EJ9bNCiA1EtJCILtMP+zYRbSCitQC+DeC6TAXMMAOhoVKb8Vnucw7qc8ag6CBEOpWgZ6IF75jbXsHPXjYXmDGMxoC+jwohFgkhJgkhxgsh7tK3/UQI8aL++nYhxDQhxEwhxLlCiM2ZDJph+uPnnzkBD31pFo4fWTqoz9l1yyU6iEFRK7/91fUHMfb2Rdh9JH0LT8sHx58+2Jm2czKFBc8UZQoSn8uBC6fVDfpzsrxxMGWLVhn6axsOAQBW7GobdAyp4A6QTH+woDOMgpwpOqhBUQtBr/C5AABtPaH0BAYgpAi6EAJXP7QML609kLbzM/kPCzrDKMTLFoc2KGoIuj99gh6OxGPaergb/9pxBD96fl3azj8QWrqCmHf3m9hyqCur12UGRr9T/xmmUHjwi7NQ5u17kFRaLoPJ0K3EXz4Y0inoaoa+eNNhAMDpE6rTdv6BsLO1Bwc7erG9pRuT60qyem2mf1jQmWOG+Sf076nLmaVDzdCD4SgA4Eh3OjP0+HU+2q1585X6N4FMsqSpFVPqSlBV7EZXb1iLhf38nIQtF4ZRcKZpUDSo2yPp7JGuZujydaYX4ugNR3HtI8tx0/+uAgB06R0luddNbsKCzjAKMkMfzGShvgT9YEf6BF3NimN6jXume84c0uM/0B4AAM7QcxwWdIZRsBsZuiZYQgg8+O52HOwIpPyMVZbcq1su3cH09UhXRVQ+RDK99ukh/RtGdbEbQLzn+2Bm0jLZgwWdYRScpuZcLd1B/PLVzXh1/aGUn+krQw+Eo2mbMZqQoesvrTL01XvasL2lOy3XPGwIuubVywdUiC2XnIQFnWEU4s25Yth6uAsvrz0IQBNmK7Yc6sJPX9qQtD0Y0Y4XAmjuCmLhSxuNbZ+UkDIoKhuCWWXon31gKc7/bXqWw5OWi8zQpeXCGXpuwlUuDKNglC3GBC689z1jeyBkLcbXPrIMrUoly9Ltrdh71I9gOC54d72yCS+uPYCJI4px9ZxGq9MMiJCV5ZLhQVFpuciVn+KDoizouQhn6AyjYLMRbJSc+S7bcQSPvL8j6fieYKLQX/Pwcvzo+fXoVbLxzjRlterEomwPisoHB1e55DYs6AxjwmG3IWwSypW723DP61uSju1NYaOoGbocIFUl8NP//T5Ou/vNQcWlZsXygSP/zkRnRwBo7daWOYhGpaBzlUsuw4LOMCacNkIokixYoUgMb29pRrsy+zOVjsqsHAACurirKxt9vL8TBwZZ0hiyLFsUuOuVjTjlrjfTKurhaAxCCPSGE+vdZYb+6JKdWPgSt/HNNVjQGcaEPxzFY0t2We67/rEVxiSbvmjuCqJC78UuZ41uOdw1pOoT1eZQPfSH39+J1u4gfvrSRvhDQy+T9IcimHjHq7jvzSYjE5fthKWg94ZjeHQJt/HNNVjQGcZEf4nutsP9N6Zq94eNBl2yQub/Ptw7pOqThDp0o8olhpmjywEAjy/dhUV9lFcOFCnaTy3fbXwrkAt+qN88mNyDBZ1hTEwe0XfTKbkIxqQ7Xu3zOLlaUqoKmcGi2kDSvonGBNz2+H/jrkEKbkcgjL+vTlgiOG7nRGPGNaNRgVhMpHWiFJN+WNAZxsSiW8/E0tvOw/T6Msv9TjtpYtfPwKDM0HtT1LADGFRtulWGHo7GEAhHcYbeddGf4uHx7tYWfPeZNUk++3++sB7feWYNNh7ojF8nEh9wDSs9Y/zhaL/fXpjhhQWdYUzYbYRR5V4sXDAt5X5/CpH2OOP/pSqKpKCnFv7u3sSMtzccTZllqw+QoDJYGQhHUeZ1wkaJlog6g/Urj36Iv63eb8xglbToVSztgfhAbygaNc5tZOixmGVcXO2SW7CgM0wKitzW8+4cNkJvikzYpdgfclC0r0zeXMf+hYeWYfqd/7Q8Vm2fK335SO0X5tkAACAASURBVFQgEIrC47TD53KgMxB/QFgJsNn+8Ti1CUOq0MvXkVjMGIiNxIThrSecr49vH0z2YUFnmBT49NmRZuw2SmltOBRBL/M6QZR8jGp7mD3ptXvbk46RqNmwtHEisRh6w1F4XTZ4XfaEDP3EhW9g/b6OhEzdLMAehxZvUNmuinjIqHIRlg+IGx5bgdV70rduKjM0WNAZJgVFrlQZui2loKt+ucdph9eZ/FBQs+FUg4xW51cFXYpuVLdcvE47fC47OgOJovvSugPYdaQn6bz+UASdvWG4lQw9FhP4eH+HYbMIER+IjcSE0WlRZeXuNnz2gaVpG/hlhgYLOsOkwOe2ztCjQiAQthZiNQMORWOWWb4q4j3Ka7U1gNVKR1bWTTgaF3Sv044Ok6BvPdyF+97cFo9PF94LfvsuZtz5TyND7w1Hcd9b2/Dp//4Aa/YmZ9yrdrfhlj9/BCBevaPS0hVM2sZkHxZ0hkmB6oer+IORlBm6EMDcsZUAgBn15UZTKxV1pqkq7upiGK09yQJpNXvVH4pACMDjss7QlzYdwT/WHMDUkaXG8QCMWapufRA3GInhw51HAQCHOpKvHY0J9Og/s9Wyd1Euf8kJWNAZJgVkZYBDm0kqBf0Xn52etP/E0eXYefclOGNitaVtc7QnLrpqhr63zW+8tsrQrSpKpPXiddpR5HYk2SIyqz9tfJURu4rboT1w/KGoIdiyJ3wqZPWOymBWeGIyBws6wwwSfyhqWBcTaouT9jvtNuNhUOpJtifaUmToe46ogp6cJffV4VBaLuYMXTJJnyxl9rqlReQPRhDQs3dzaaMZtyNZNmKcoecELOgMM0hCkXhNdpk3WbCdaqWLhd/c1mMt6JsPdRlL4B3pGZiHLvHqlkuq/ugTR2gPHn8ocQWl5s6gHkc0YcC0L6y0mzP03GBAC1wQ0XwAfwBgB/CIEOKXKY77HIDnAJwihFiZtigZZpjY/otLEBMCy3Ycgdthx1PLduPFtQeMRS0sBd0Rtyys9rf541l0u/J686FOzGgow7bD3daWSx+Zs8dphzdFVQ4A1Fd4AQCBUCThIdLSpXnp/lB8XKCnn4oVK7+cBT036DdDJyI7gPsBXAxgKoCriWiqxXElAG4FsDzdQTLMcGG3EZx2G86cWIM5Yysxd5w24HlEH7Qs9SaLqMtUi25GtVwOtGuLTwshsPlQF6bUlaKq2GX0IVcxe+guxfqQZYsqctk4APDpYu8PRdGmePjNXTJDjxiZeY+plNJssVjVyLPlkhsMxHKZA6BJCLFDCBEC8DSABRbH/QzArwAMrskzw+QRUjSPdIfgsJFlnbkqtJaCrtspI0rd2NemCXpzVxDt/jCOH1mCESUeY3FmlVA0lvCwUIVWWi4qZ0+qwcgyD2Y0lBlxBsLRhAeKvI4/FDVaFPhNs1fV8959+XTLbJwz9NxgIJZLPYC9yvt9AOaqBxDRyQBGCyFeIaL/SGN8DJNTyEz3SHcIXpfdshLG2U+G/tdV+wAA42uK8fH+DuN8AFBb4kZtqRsblGZZktauEMp8TqPm2+2wowtaNu1x2BNKJBcumIYvnDIaTr0zpM1GcDtsCIQSBV3qsGrDmCc7+VwOtPnDmKSvifrMir0ww4KeGwx5UJSIbAB+B+D7Azj2JiJaSUQrW1pahnpphsk6sgyxpTuYsjVAf4IumVBbjM7eCDoCYfTodkeR24ERpR4c6ug1rI2WriA+/+C/sOVwF86eVGN8PjFDtyWUSE4bVQa3w66tkaoPtPpcdvhD0QTfXqIOhJoHRWXDMflzWdkrLOi5wUAEfT+A0cr7Bn2bpATACQDeIaJdAE4F8CIRzTafSAjxkBBithBidk1NjXk3w+Q8lXoN9r42v5Gtm1HruKWgn9RYjre+f3bCcbLkcX9bwMiKfS4H6ko9CISj6NK3rd7Thg93aZN+5k+rMz6vCro2KBp/wFjVknudmqDLDN1hix+jirx5UFT+nNJKshR09tBzgoEI+goAE4loLBG5AFwF4EW5UwjRIYSoFkKMEUKMAbAMwGVc5cIUItXFmqCHo8LSPwcSB0VLdUGPxQRGlXsTjpO14ZsOdhq+dbHbgdpSbTDzsD6bU5YinjWpBpPr4otvqF69z+VIyNCdFrNcvS47AuEI2vxhEAFVxfEJQtLLB5IHReXPKX8uOTZ77dxG3HHJ8frPZ3UnmGzTr6ALISIAbgHwOoBNAJ4VQmwgooVEdFmmA2SYXEKdJVmUoteLKqbymN5wDG6HDTeeMdYQ4pMbK9BQ4cXfVu83RLTIbUddqQcAcFivEZeLYCy8bFrCudUMvcTjQLFHFfTkDN3ncuiWSwilHqfROteMua2BzPxl3NIKumZuI04+Tlv+jjP03GBAdehCiEUAFpm2/STFsecMPSyGyU2cdhvKfU60+8OoK/NaH5MgtFqGXuZzgojw409PxfcvnIxdR3rgcthw+Un1+O+3mzBH7/9S5NI8dAA4pFegyMUs3E4bHIpQy2n7Mq5i5QHjsCXnaj6XHe9s0cauxlT5Elr9mily2Q3rJTlDF8Y1bKTFFmMPPSfgmaIMM0jKdRvluEqf5X7Vcqkv9+KeK2bgj9ecZGzzuuw4Xm+WNXFECYQAmpq7AcQHRYF4SaGciu922I2qFSDeWEuiLsjhsMjQbzlvQvxn8LkMD72+PPnBpH4TkYO/8tuBzMZtBGNmKw+K5gYs6AwzSKTANqYSdEeimH5+9mjUlngsj5XivaO1G047weXQFqoo9TgUQdcyZbfDnKEn/vctdvftoZ85sQYn1GsPkgqf07BQqouTm225TDXuAGA3PSRsNoJNL9tkyyU3YEFnmEEi/e7RKQTdSkxTMUIfAN3Z0pOQYdeVxScXyQk/ZkGXoistEVXQ1QoWFenPVygZus1GeOmWM7DktvOMFZbUbxny/HZ950Nfmo3rThuDsVVFRobOlktuMCAPnWGYOHLQsLEqHYKuCWxPKIp6pc/4iFJPwqCo3UZw2G2wKcIpPXT5IEi0XKxjkNcr97ng1NsOOGyE6Q1lRuyhSMxUQaNdRz4jJtQW487LtAW0DcuFM/ScgDN0hhkk/37WOADxbNfMYATd47Qbtepq1UxtiQdNzd1oau5CMBwzVhayKZm3zKLl59TrpuppXqV740VuuyHaduWcTv21mqF7DEFPPid76LkFCzrDDJIfXjQZ239xSYIQqqRa6SgV0nZJtFzc6A5GcMHv3kMwEjPW/lSRg6JWi2hYVblon9HOE4rEDMtFPVZW6DgtLBerNgfShuHmXLkBCzrDDBIiShBzOTX+xNFaTXYKLU2JtEFUYbYr4hkIRy0XlZCo3rkkVYYuzxOMxAzRVn8WKe4uh83I4OPHJZ9PfjbSx+IbTPZgD51hhsiHd1yASFSAALyy/iAaKqy99VRMqSvB+9taE2yLsyfX4r63mgBoqxdZCbqsT7dazDrV8nlXzGrAe9ta8fWzx+NnL28EkDiA6tIfBC6HDa/deibW7G03BmWtvpFIC+hYzdCjMYH3trbgnMk1Ke95NuEMnWGGSKnHicoiFyqKXPjiqccN+vOfnjEKAPCvHUeMbbOOq8A9n5sBQGsEpk4ikshvBmOriwZ8rXKfC0/eMAd1ZR4ji0/w0PUHR7HbgXE1xbj85AYIaGLdl+XSx2JKBc1D7+3A9Y+vwOJNzcMdCgDO0Blm2JnRUIax1UX4kulhIPvANHcGMbIseQD27Mk1mDm6HJfOGPmJrisrYdRSSJmtqzaOLEm0Wwi6tJeO1SqXPUe1dWCbu3JjGQgWdIYZZogIb//gnKTtcjWklu4gxlQlZ+E2Ilx+csMnvm7cG7clbStR+sJIJ8hqDNgYFD1mq1xy6+dmy4VhchRZzihE8jR/wNrTnqJ0Y+wP6ZerHrr08dVGX3KbzeJ6x3rZovxiQhh+/xzgDJ1hcpZST3xxDKtBUSsL5G/fOD1pgYpUOCyqXHr1NgMlyrXlgKe15XJsD4rm2o/NGTrD5CilXlXQkwdFrTJ0r8uOKmVx6L6Q9oqaocuKlhLVQxd9ZOgUz9APdfQes5l6DhS4AGBBZ5icpcTtMITCMkNPMbFpoFhVuQTDMkNP9tCtREt+tiMQxtm/fhuvrD84pJgywT/W7EdTc1dGr5Ejes6CzjC5is1GRrWJ1UxRq4x5MMgMXRXqXr2TZLFVhm5luejb2vxhBCMxNHfmRrWHyq1Pr8GF976XkXMLHhRlGGagSB99oB76YIgv+hzfFtIFXfXQZc+a0RYTpqRdE9B9e9laOFeQFlCmnaBcsVx4UJRhcpiKIif2twcGXOUyGKTlIixG9lTL5bMn1aPC58I5k5MXdpffEmQHSmnZ5AoDHSAuFDhDZ5gcZs6YKgDWvVKsLJDBIDN0q0oNVdCJCOdOqU05td1uo7ig51iGbl4fdaj8eflu/Gt7fEavvHe5MlOWBZ1hcpjzj68FEF+iTmWoGbqcIWpVcmjV8CsVdiIjE841QZeLkaSLO/72Ma5+eFnS9kgsN35utlwYJoc5dVwVrjttDD4/e3TSviELuk1aLhb7BtEC2GZTLJdIrlku2YknnCPdJlnQGSaHsdvIWB3Iat9QsBm9zOPbfnrZtEGXHtqJEAhLDz1zmWo4GkNMCMua/FRIQR9sj/qBIm9dJEc8F7ZcGCZPGWqVi/TE1UHRr5w2Bs9+bd6gzmPLgIe+9XAXxtz2SoLVdPEf3sfkH782qPP06FZQqv7wgyHch2hHcmRCFQs6w+QZMjEf7EIaqc4zVCmy2wiBNFsuf1u9HwDw2sfxbwtW4wj9IeMajIWU8lwWFTzyWdiX2GcTFnSGyTOkVTJUy0Um+EPtw5JguURieOGjfXhj4+EBfXbDgQ5LMZQWxmCEeM3e9qQyRTkomipDb2ruxqX3vY92f6jf8/da+PFRfTA0V1oesKAzTJ5hCPoQLRcrD/0TncdGhqAFwzF879m1+PcnV/b7ue0t3bj0vg/w69e3JO2Tg4yOAT60OvxhfOb+JfjO02sStksrKNXC3Wv3tmPDgU7sbO1J2C6EwFubDycItdUAa1jfnyuDoizoDJNnkGG5pMdDT0eGLhmM5XJYbxOwdm970j6ZtQ/0W4j0ytft60jY7jcsF+vzdATCCcdJXt9wGDc8vhKPL91lbLOyXOQ3ibwaFCWi+US0hYiaiOg2i/1fJ6L1RLSGiD4goqnpD5VhGCCeWQ80e019Hu1vq5migyGhuZcyKCqEQG8fM0dl6baVaMuJVFYiaoXMpM3nkhZMqm8zqQRdrkC0oyXu21tm6HqckZjA0u2taOtJtm52tfagwx8e0M8xVPoVdCKyA7gfwMUApgK42kKw/yKEmC6EOBHAPQB+l/ZIGYYBoA6KpsdyGWpPb3VwVhX0+99uwpT/eg2dvcliduMTK/HFPy0HYC3oMtP3Bwcm6PJ480Bxj/75VJZIXNATvXd5b9QZulYPJ/lNIhCK4pqHl+P6x1cY+15ZdxAn/H+v45zfvINL7nt/QD/HUBlIhj4HQJMQYocQIgTgaQAL1AOEEJ3K2yLk2rpMDFNADHXKv0SeZaiWi0NRUbWXyxv6wsnPrtiL3Ud68NB72419izfFB02tBF0KrbRSQsqDwmq5O9nH3ZyJB8L656MxdATCSd0gU2XocjA1HIshGhP441vbDItIRQp+mz6oqlbiLHx5A7r18+xvDyR9NhMMZGJRPYC9yvt9AOaaDyKibwL4HgAXgPPSEh3DMElcOK0Oz3+0b8iTZRr07okzGsqHdB5Vj3sUYRxV5sHavcCLaw/gsSW7sL89gC+c0mgsrSexskPapdDqGbY6hT8UjcFjS5xcJLNn87eWeIYew/m/fRet3UHs+uWlxn7jwWFqEdCmWySBUBTLdx7Bb/651fJnlxl6u368S+mKORxtENI2U1QIcT+A+4noGgA/BvAV8zFEdBOAmwCgsbExXZdmmGOKuy+fjh9cNAkeix7pg2F6Qxle+86ZmFQ78HVIrVAzbCmQAHCkW8taNx3sNCwPq+zayjoyZ+g9IZOgO82Cbp2hSyslHImhPZRs/cjrBEwZuixjbO0OwudKLZOyykVm6OpDNpOzZlMxkEf8fgBqI4kGfVsqngbwGasdQoiHhBCzhRCza2qSW3EyDNM/LocNI8u8aTnXlLrStHnxZpq7ekGU6F9b1ZxbZeidJiukR/HSwxaZr8zQzfaNzJLVGH728kZj0DP+4EgUdCnQLV1By5/t/rebEI7GjOoW+Y0iMUPPfl+bgQj6CgATiWgsEbkAXAXgRfUAIpqovL0UwLb0hcgwTC6TqrRwf3sA502uTdgWshJ0vaTw1fUH0e4PQQiRZIV0K5bIrJ8vxqumfjNycWsbEe59Yyv++JYmQVLQ1ev+6YOduOc1rfY9nqGbLJcebXtLV9CyJPHXr2/BX5bvUSwX7QGgTmAajrlG/Qq6ECIC4BYArwPYBOBZIcQGIlpIRJfph91CRBuIaA00Hz3JbmEYpjBJJejhqMC0+rKEVrxW1SZ2Iuxo6cbNf/4IP3xuHXa29hjHyQzdXIXymFIfDsQtE7uNsHjTYby3tRVA4mCqSpFLs2z6y9B7QlF0pWjB+8q6g8agqIzXNYjGYZlgQB66EGIRgEWmbT9RXt+a5rgYhskT+qq6qS52oabEbWTYlpaLjbB6jza5aOvhLry7tQUAMHN0Obp6rQctzXXdci1Uu43Q3hMyWgakEvS6Mi96w1Fjv9lDb1PO3xmwriH/aE8bRpZ7Era5LJYKzCY8U5RhmCHR12zOyiJN0CVWAhsTAh/taQOgWSTvb2vFuOoiTBlRgkMdvejwh9FtqkfvCGhT/X/28kbtc7qH7rAROgMR4zpWFg+gzbZVB3DVQddF6w/iSE8Qoyu1cYpUgh6JiaSfx5WGro5DgQWdYZgh0VdPGbOgW2Xo4WgMa/dpGfrBjl5sOtiJ8bXF8Lrs8Iei+MwDS5Iz9EAYa/a2408f7ASglC0Soas3bAxIpsrQQ5FYgqCrdegPvbcD42uK8Y1zJgAAOntTr3rUbvqm4BhqC8whwoLOMMyQ6EvD6su9qClWBV0ktRoIRWLY3xZAXalmXxzs6EWRy45DHVolys7WngTxBZJbAsiyxa5gBDERF/JUbW2DkahxTpfdluDRH2gP4OTGciMemaEvXDANU0eWms6TeH65FF1fLQ8yCQs6wzBDQlou9eXJpZSjyr0JNePhaCzJBukJRtHmD2NCbbGxzed24FvnaxlydbEbR7qtywclUkCP9mjHGZZLJJYwKPuj+VPgddq1DF3PruvKPMYEpnA0hpbuIEaWeeHVB05lhn7a+CpcfnJ9n3HI63b1kdVnEhZ0hmGGhBwUnTm6LGmf026DWxkoDEVjRjYtOdChTYsfW11kbCt2OzBtVBm+dtY4dPaG0WrR9EpFli3KyUzyoRGKxFDkjj9QfC47XA5bguVSV+YxLJfDnb0QAhhV7oHPEHTtOIfNlrINryRoCHqy756Nnuks6AzDDAkpVFPqSi33y0wX0CYFBU12xP42TdDH1cQFXYppqdeJUCSGA+2BhEzbjHxIyKXg2v1h3PzUKnQFIyhSPueVgh6NC/qoMo8xKHpQt3nqyrzw6t8sZLbtsFO/gi4fJAfak/u+ZGOiEQs6wzBDQmaw1YpXrnLN3EYcr3vP4ahIytClCKsZepE+3b5U7/uys7UHI8sSSwQlveGopWf96seHACDhQeBz2eGy2xBUMvTqYreRWR/Qm2iNKvPELRf9OKfdlrKvukRaLh/uPJK0rzsYybi3zoLOMMyQkMJYWZTYdOu7F0wCAJR6nHjg2pMBAKFo1LBHzIyrVj10TUxlI692fxh1KQS9MxBOekio+JRvCF6nHW7FcilxO+BzaZ66EMIYiB1Z7jV6uMQtFzJ6taQq1ZSCvmzHUUyvT7Sgrn14OU775Vsp40wHaWvOxTDMsUlnQLMkyn0ulLgd6ApGsPPuSxKOkVPiwxHrRS+INN9aIrNqtTNjqgy9PRDu084odsfP4VU89M5AGKVepzEZKBwVaOkKwuu0o9jtQK8tmvDzOWzxDL3M68RRC1+/uSuIu1/dhLX72nHN3EZsOdRl2DDb9Na6HYFwUsfJdMGCzjDMkIhn6C4s/v7Z2H3EbyxvJ5GZrdWgKABU+lwJC0LL7LjUE5eoVA3JOgLhPq2M4oRBUUeCh16mCHooGsPRnhAqi1wAALfDBqL4AKfqoVtl6A0VXuxrC+B/3t0BAKgr9RjXUtl4oBPzxleljHcosOXCMExaqPC5MKLUgzljK5P2SSEMR2OW4lvmS8xYZa+VAWXo/r4tF/UcPlei5VLmdcYfNpEYjvpDqCrWBJ2I4HPaDX9dE/Tk5f/k2MGkEYltiCuKXAkVPpKNBzuTtqULFnSGYdJCuS+1jeDUhS0QjuIXizYBAF665QxcM1dbF8FsQfgsLJcTG60X4li9pw1bDnWlvPa0UXEv2+tMLFvUMnTt4RGKaBl6hc8VP17phe5UyhbtNsKvr5iBR748Gx0BzXqZqNTRA9q3DnNvl9oSNxatP5hyButQYUFnGCYt9FXSJzPbNXvasVkXX4/TZmTHpZ5EQZc2Saki6JNHJC/EMbrSiwfe2Y5QNIYzJ1ZbXtvttOGUMRUAgBKPw6hyCYSjhqcOxAW9qigu6HJA1UbaQhxyar/DRrhy9mhcMHUE/nzjqbj5nPFJ3zLMGbrPZceP5k/Bqt1teOSDHSnv1VBgD51hmCHxq89Nx7+2J5fpqThtcZ9a4nHaDaFPytD1zNhpt2HaqFJcMn1kki8PAM/cNA9/WLwNLd1BzGgow/vbWpOOcdltePKGuVi9pw3letYcisQQisTgdtgUDz2qZeiKoMtadOnvuxxaDOqiIHPGVmLO2Eo88n6iSFf4nAkZel2ZB5+b1YBijwPnTM7MAj8s6AzDDIkvnNKIL5zS95KSWnZLCU221AqTUm+iFBUpVscr3z4z5Xmri9341RUzAAAPvNMEQLND1FmZLocNXpcdp02o1t/bEdJbELgc8W8Jnb0R+ENRY1AUiE+Kkp65mqGbMdsrlUUuuJX+6KfpA6EXTatL+fMMFRZ0hmGygtNuM2ZdPvjFWSjzOg2BLPGYPfTUC0WUehxGfxVVRKUwVxa5EpaOMwuty65l6MGwlqFLW+SwXoNeaWG5SAGX1S1WPeDNi3aXerQHVoXPid9fdRLmjctMZYsKe+gMw2QFl8NmTLGXNeeyG6JPtzZkmWIqP/7lb52Bxd8/23Kf/Ix5xqpZaF0OzUM3MnRd0OW0f3VQVAq6PLdsFGk1Y9T84LDZyLB0zp5Uk5XFLzhDZxgmKzjtNmOxZ5dS9QLErY1Xvn2mMWhqxQn1yQ3A1PMDQE2JG5uUJUfNQup22NAbjiIaE3A74oOiTS3dxuclsspFCrhsj2vVA96q+Zb2DSB7y9KxoDMMkxVcdkJrd7wHORBf+k0K+uhKH0ZX+vo91/s/PBetppa6coC1uthl2p4s6HJJPNVDf3ntAZR5nZjREH9oyG8O0hqSg7Vq3xmJWl8/X/fJvS67MbCaDVjQGYbJCk5l1qRbFzkjQx+k6FkJv8y0zZaLeXKPmrGrVS6dvRFcMash4QHgNSwX7WExua4ED31pFs6wKJGUP8uNZ4zFjz89FQDwrfMmJi3OkUlY0BmGyQqqUMqsWPYhT0cWa1guZg/dYlBU3acKvnlFIino6lT/C1NUqZR7tW8GjVXxB83xI61bCmcKFnSGYbKC0ySkAHDZzFF4Y+NhTG9I7Y0P9vzVJYmWS5KgJ2To9oT3xZ5ESZSWS3990AHgilkN8LntuOSEkYMLPI2woDMMkxVcSmWIzIr/beYo/NvMUWk5/9hqHyp8zqSFNqyqXNTX6vtSk6Abdej99EEHtKqWT89Iz8/ySWFBZxgmK1hZLulkQm0JVv/kQmOg1bhuPx662x63e5Lq4WWVS18rYecQ+RElwzB5jxR0p50Sps6nm748cwAJZYTmDN28zJ3PNCia63CGzjBMVpCZciaycxW7jfCHq07EtFGa9eIxDbiqou02CXpJKsslTzJ0FnSGYbKCFHJ3FuqyF5xYn3KfKtpuhy2hgiVpUHQQHnouMKDHDhHNJ6ItRNRERLdZ7P8eEW0konVE9CYRHZf+UBmGyWfkgGOmM/T+SBT0xIeLuY2vuZdLrtPvnSUiO4D7AVwMYCqAq4loqumw1QBmCyFmAHgOwD3pDpRhmPxG9jbPRk+TvlAHPq3aAqh4TO1zc52BRDkHQJMQYocQIgTgaQAL1AOEEG8LIfz622UAGtIbJsMw+U6J0XhreLNds4euYu65Hu/LXiAZOoB6AHuV9/v0ban4KoBXrXYQ0U1EtJKIVra0tAw8SoZh8h5pZ0QsmlhlE9Vy6e/bgi/PBkXTGiURfRHAbAC/ttovhHhICDFbCDG7piYzK3YwDJObyEUsgn0s6JwN1KqX/johmhe4yHUGUuWyH8Bo5X2Dvi0BIroAwB0AzhZCBM37GYY5tpHedW8k2s+R2aPfDN2ZX1UuAxH0FQAmEtFYaEJ+FYBr1AOI6CQA/wNgvhCiOe1RMgyT90jLZbgzdBXpoU8dWYoqU9tdQBsMddlteTMo2q+gCyEiRHQLgNcB2AE8KoTYQEQLAawUQrwIzWIpBvBXfVBhjxDisgzGzTBMnmFYLjmUoUsrZdGtqdctHVHmRnVRstjnIgOaWCSEWARgkWnbT5TXF6Q5LoZhCgxpuQzzmGgC5qoWK56/+TSUuJ39HpcL8ExRhmGygrmTYb5QW+IZ7hAGTH4YQwzD5D3mToZM+snPRybDMHnHcM8QVXn5W2dg9xF//wfmGSzoDMNkjYULpmFmQ/lwh4ET6stwQv3QV0nKNVjQGYbJGl+eN2a4Qyhocuc7EMMwDDMkWNAZhmEKBBZ0hmGYAoEFnWEYpkBgQWcYhikQWNAZhmEKBBZ0hmGYAoEF9jwkgAAABVBJREFUnWEYpkAgIYan9RkRtQDY/Qk/Xg2gNY3hpItcjQvI3dg4rsHBcQ2OQozrOCGE5ZJvwyboQ4GIVgohZg93HGZyNS4gd2PjuAYHxzU4jrW42HJhGIYpEFjQGYZhCoR8FfSHhjuAFORqXEDuxsZxDQ6Oa3AcU3HlpYfOMAzDJJOvGTrDMAxjggWdYRimQMg7QSei+US0hYiaiOi2YY5lFxGtJ6I1RLRS31ZJRG8Q0Tb974osxPEoETUT0cfKNss4SOM+/f6tI6KTsxzXnUS0X79na4joEmXf7XpcW4joogzGNZqI3iaijUS0gYhu1bcP6z3rI65hvWdE5CGiD4lorR7XT/XtY4louX79Z4jIpW936++b9P1jMhFXP7E9TkQ7lXt2or49m7//diJaTUQv6+8zf7+EEHnzB4AdwHYA4wC4AKwFMHUY49kFoNq07R4At+mvbwPwqyzEcRaAkwF83F8cAC4B8CoAAnAqgOVZjutOAD+wOHaq/u/pBjBW/3e2ZyiukQBO1l+XANiqX39Y71kfcQ3rPdN/7mL9tRPAcv0+PAvgKn37gwBu1l9/A8CD+uurADyTwd+xVLE9DuAKi+Oz+fv/PQB/AfCy/j7j9yvfMvQ5AJqEEDuEECEATwNYMMwxmVkA4An99RMAPpPpCwoh3gNwdIBxLADwpNBYBqCciEZmMa5ULADwtBAiKITYCaAJ2r93JuI6KIT4SH/dBWATgHoM8z3rI65UZOWe6T93t/7Wqf8RAM4D8Jy+3Xy/5H18DsD5RETpjquf2FKRlX9LImoAcCmAR/T3hCzcr3wT9HoAe5X3+9D3L3ymEQD+SUSriOgmfdsIIcRB/fUhACOGJ7SUceTCPbxF/7r7qGJJDUtc+tfbk6Bldjlzz0xxAcN8z3T7YA2AZgBvQPs20C6EiFhc24hL398BoCoTcVnFJoSQ9+wu/Z7dS0Ruc2wWcaeT3wP4IYCY/r4KWbhf+SboucYZQoiTAVwM4JtEdJa6U2jfoYa9LjRX4tD5/wGMB3AigIMAfjtcgRBRMYDnAXxHCNGp7hvOe2YR17DfMyFEVAhxIoAGaN8CpmQ7hlSYYyOiEwDcDi3GUwBUAvhRtuIhok8DaBZCrMrWNSX5Juj7AYxW3jfo24YFIcR+/e9mAH+D9ot+WH6F0/9uHqbwUsUxrPdQCHFY/w8YA/Aw4hZBVuMiIic00fyzEOIFffOw3zOruHLlnumxtAN4G8A8aHaFw+LaRlz6/jIARzIZlym2+bp9JYQQQQCPIbv37HQAlxHRLmi28HkA/oAs3K98E/QVACbqo8UuaAMILw5HIERUREQl8jWACwF8rMfzFf2wrwD4x3DE10ccLwL4sj7afyqADsVmyDgmv/Kz0O6ZjOsqfcR/LICJAD7MUAwE4E8ANgkhfqfsGtZ7liqu4b5nRFRDROX6ay+AT0Hz998GcIV+mPl+yft4BYC39G88aSdFbJuVBzNB86rVe5bRf0shxO1CiAYhxBhoGvWWEOJaZON+pWtEN1t/oI1Sb4Xm4d0xjHGMg1ZhsBbABhkLNO/rTQDbACwGUJmFWP4P2lfxMDRv7qup4oA2un+/fv/WA5id5bj+V7/uOv0XeaRy/B16XFsAXJzBuM6AZqesA7BG/3PJcN+zPuIa1nsGYAaA1fr1PwbwE+X/wIfQBmP/CsCtb/fo75v0/eMy+G+ZKra39Hv2MYCnEK+Eydrvv369cxCvcsn4/eKp/wzDMAVCvlkuDMMwTApY0BmGYQoEFnSGYZgCgQWdYRimQGBBZxiGKRBY0BmGYQoEFnSGYZgC4f8B0Er9IronvRUAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55yoCnZCMMzh"
      },
      "source": [
        "<div class='alert alert-block alert-warning'>\n",
        "            Questions:</div>\n",
        "            \n",
        "- What do you see with a simple application of LSTM models ? List the possible reasons for that result (these could be linked to the data, the way it is pre-processed, the architecture, and the training procedure). "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The LSTM are a special kind of RNN, capable of learning long-term dependencies, they are designed specially to avoid the long-term dependency problem, remembering information for long periods of time. The accuracy of LSTM model seems to be better than all the other models, but if we limit the size of the sentences taken, the LSTM will be less usefull for smaller sentences. If the min_freq get higher we can easily imagine than the accuracy of lstm model will decrease. This is due to the architecture of LSTM itself and to the pre-processing of the data which is built to learn well long term dependecies (if there long term dependency = for larger sentences)."
      ],
      "metadata": {
        "id": "bQAYX9w35tZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"########### LSTM ##############\")\n",
        "for freq in [5, 10, 15]:\n",
        "  print(f\"--------MINFREQ = {freq} ----------\")\n",
        "\n",
        "  training_dataset = TextClassificationDataset(train_texts_splt, train_labels_splt, min_freq = freq)\n",
        "  training_word2idx, training_idx2word = training_dataset.get_vocab()\n",
        "  valid_dataset = TextClassificationDataset(val_texts, val_labels, (training_word2idx, training_idx2word), min_freq = freq)\n",
        "  test_dataset = TextClassificationDataset(test_texts, test_labels, (training_word2idx, training_idx2word), min_freq = freq)\n",
        "  training_dataloader = DataLoader(training_dataset, batch_size = 200, shuffle=True)\n",
        "  valid_dataloader = DataLoader(valid_dataset, batch_size = 25)\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size = 25)\n",
        "  \n",
        "  \n",
        "  model = LSTMModel(100, len(training_word2idx), 10)\n",
        "  # Create an optimizer\n",
        "  opt = optim.Adam(model.parameters(), lr=0.005, betas=(0.9, 0.999))\n",
        "  # The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  train_losses = experiment(model, opt, criterion)\n"
      ],
      "metadata": {
        "id": "DrLvhgDCY6oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsPQtHgBRiVl"
      },
      "source": [
        "## 6 - Fine-tuning a Bert model\n",
        "\n",
        "Fine-tune the lightest BERT model available on IMDB data and compare it with previous results ! You should simply follow the tutorial and slightly adapt it to our way of obtaining the data:\n",
        "https://huggingface.co/transformers/custom_datasets.html#seq-imdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeihrVgpMILu"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import get_scheduler\n",
        "from datasets import load_dataset, load_metric\n",
        "from torch.optim import AdamW\n",
        "from tqdm.auto import tqdm\n",
        "import torch"
      ],
      "metadata": {
        "id": "tMqi68UzvllQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('imdb')"
      ],
      "metadata": {
        "id": "H3cbARK2vtV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "  return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "2CocRZeFUURH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset[\"train\"]), len(dataset[\"test\"]))"
      ],
      "metadata": {
        "id": "BWqoyOiwsDoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1500))\n",
        "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(100))"
      ],
      "metadata": {
        "id": "jp0-mDavV_FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS6apFUyMTdE"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=10)\n",
        "eval_dataloader = DataLoader(small_eval_dataset, batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
        "\n",
        "\n",
        "num_epochs = 3\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "5EHcoKwjgdN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)"
      ],
      "metadata": {
        "id": "U7zEK7z_gaLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "model.eval()\n",
        "for batch in eval_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "metric.compute()"
      ],
      "metadata": {
        "id": "sJ4SDTvMhIGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that we do not have enough GPU space on colab to load and train the model, so we could not verify the performance of this model, but according to the state of the art BERT is a very powerful model (in theory more than those studied in this tp) for embedding sentences."
      ],
      "metadata": {
        "id": "otu7w9T1NTNA"
      }
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}